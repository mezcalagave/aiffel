{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0038/aiffel/my_rsp_full/my_rsp/test/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp/test/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0038/aiffel/my_rsp_full/my_rsp/test/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp/test/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0038/aiffel/my_rsp_full/my_rsp/test/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp/test/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3916 입니다.\n",
      "x_train shape: (3916, 28, 28, 3)\n",
      "y_train shape: (3916,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_train_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data= 3916   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp\"\n",
    "(x_train, y_train)=load_train_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 3.3552 - accuracy: 0.3378\n",
      "Epoch 2/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 1.0979 - accuracy: 0.4180\n",
      "Epoch 3/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.9301 - accuracy: 0.5546\n",
      "Epoch 4/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.7074\n",
      "Epoch 5/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.6455 - accuracy: 0.7403\n",
      "Epoch 6/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.4829 - accuracy: 0.8090\n",
      "Epoch 7/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.4066 - accuracy: 0.8394\n",
      "Epoch 8/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.8700\n",
      "Epoch 9/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3174 - accuracy: 0.8787\n",
      "Epoch 10/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.9025\n",
      "Epoch 11/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2788 - accuracy: 0.9022\n",
      "Epoch 12/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9162\n",
      "Epoch 13/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9265\n",
      "Epoch 14/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.9224\n",
      "Epoch 15/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1872 - accuracy: 0.9339\n",
      "Epoch 16/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9379\n",
      "Epoch 17/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1789 - accuracy: 0.9392\n",
      "Epoch 18/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1381 - accuracy: 0.9505\n",
      "Epoch 19/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1412 - accuracy: 0.9558\n",
      "Epoch 20/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1167 - accuracy: 0.9563\n",
      "Epoch 21/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1377 - accuracy: 0.9545\n",
      "Epoch 22/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1351 - accuracy: 0.9556\n",
      "Epoch 23/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1582 - accuracy: 0.9494\n",
      "Epoch 24/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9594\n",
      "Epoch 25/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08683c1150>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,  y_train, epochs= 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.8441923260688782 \n",
      "test_accuracy: 0.7333333492279053\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=3)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_train_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_133 (Conv2D)          (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 2.3293 - accuracy: 0.4860\n",
      "Epoch 2/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.7091\n",
      "Epoch 3/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7960\n",
      "Epoch 4/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8598\n",
      "Epoch 5/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8767\n",
      "Epoch 6/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.9150\n",
      "Epoch 7/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9242\n",
      "Epoch 8/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.9428\n",
      "Epoch 9/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9448\n",
      "Epoch 10/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9637\n",
      "Epoch 11/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9635\n",
      "Epoch 12/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9612\n",
      "Epoch 13/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9796\n",
      "Epoch 14/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9852\n",
      "Epoch 15/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9893\n",
      "10/10 - 0s - loss: 1.8753 - accuracy: 0.6333\n",
      "test_loss: 1.875349521636963 \n",
      "test_accuracy: 0.6333333253860474\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_109 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 26, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,799,626\n",
      "Trainable params: 3,799,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), input_shape=(28,28,3), activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64,(3,3),padding = 'same', activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), padding = 'valid', activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Dense(256, activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
