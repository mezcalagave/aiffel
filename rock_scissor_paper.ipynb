{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0038/aiffel/my_rsp_full/my_rsp_final/test/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp_final/test/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0038/aiffel/my_rsp_full/my_rsp_final/test/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp_final/test/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0038/aiffel/my_rsp_full/my_rsp_final/test/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp_final/test/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3916 입니다.\n",
      "x_train shape: (3916, 28, 28, 3)\n",
      "y_train shape: (3916,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_train_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data= 3916   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp_final\"\n",
    "(x_train, y_train)=load_train_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUHUlEQVR4nO3dXYxc5XkH8P9/Zmf2w7vrbxZjDJjIqJCKknaFKlFVVFEjwg3kIm0cKSISqnMRpETKRRG9CJeoahLloorkFBSnSgmREgQXqA1CkVBuEhbkgKlDDcbBxsYL2LDr/ZyPpxc7RAvseZ5lzsw5E7//n7Ta3XnmPeeds/PMmdnnvO9LM4OIXP4qZXdARIqhZBdJhJJdJBFKdpFEKNlFEjFU5M5GR0dtcnIy+w5RYYA97c4nkqdqwT73O9fm+1yMsX4/ePmQubk5LC0tbXjQcyU7yTsAfB9AFcB/mNlD3v0nJydx8B+/nBmPEsr6+rxp+/vOkewV5suoapDODPruqeRM9uihrQ7VMmOXc9m3rMf22GOPZca6fhtPsgrg3wF8HsBNAA6SvKnb7YlIf+X5zH4rgFfN7KSZrQL4KYC7etMtEem1PMm+F8Dpdb+f6dz2ISQPkZwhObO0tJRjdyKSR55k3+iD5Mc+qJjZYTObNrPp0dHRHLsTkTzyJPsZAPvW/X41gLP5uiMi/ZIn2Z8DcIDkfpJ1AF8C8GRvuiUivdZ16c3MmiTvA/A/WCu9PWJmL3tt2u02FhcXM+OMarKV7HjUtlLxX9cY1JC87Uf7bjWDMgyjsp/f3C3ztPPtm1H7gDHN67bKKr15+81VZzezpwA8lWcbIlKMNF92RRKkZBdJhJJdJBFKdpFEKNlFEqFkF0lEoePZq5UqJie3Zcaj2mTbiRtabttw+GyOuJm/79pw3Y1Hw0RzPbZWzqG7VT8c1fEXnOsq8gqvyyhRq+X/zfql3c7+e+vMLpIIJbtIIpTsIolQsoskQskukgglu0giCi29LS8v45VXXum6fcspK4RlO6ftpuLWdOOe5eVlNx6V7iK5hlPm3Hek3d8pgbs2yGW7PLznms7sIolQsoskQskukgglu0gilOwiiVCyiyRCyS6SiELr7M1mC2+/825mPM900HHbvFNNdz+V9NatW9143jWdmWMp1n7Xm+vOKq555el7vx/38PBwX7ef5cSJE5kxndlFEqFkF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRhdbZh0dGcMMNf5YZ7+eyyfnjbtjVbPpj4S1aNjnYufVxKeu8fcNq9/MA5P2blbVtABgaKjS1/qhazZ77O1ePSJ4CMA+gBaBpZtN5tici/dOLl5+/M7N3erAdEekjfWYXSUTeZDcAvyT5PMlDG92B5CGSMyRnVlb8udhEpH/yvo2/zczOkrwCwNMkf29mz66/g5kdBnAYAHbu3J1jZkQRySPXmd3Mzna+zwJ4HMCtveiUiPRe18lOcgvJiQ9+BvA5AMd61TER6a08b+OnADzeqUcOAfgvM/tvr0G1WsH4+HhmvJ/LJkfzwuebd95v69U+AQCV6M8Q9N2ps4fTtkc1fAZ9D9oP17ufgyCSp1be7zp7dP1Cv3j97jrZzewkgL/otr2IFEulN5FEKNlFEqFkF0mEkl0kEUp2kUQUPA6PqERlKLe1E2O+hxKMrs3VuJ1nSWXE5bO2Mww1bttFh9a3Dx5brZ0dv5xLb2VNJe2V/HRmF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRSnaRRBRaZ2eFqI149Ud/KGfVq5sGpex2M98Q2Fo1+3UxmjbYG4IKAI3Gih9v+dMxV7zXbKffa42jaar9A1sZ8q+bqDf6NzlRnlp5NAQ1zxLeeeP9aqszu0gilOwiiVCyiyRCyS6SCCW7SCKU7CKJULKLJKLQOnulUsHY+Ghm3FrdT/fs1eABgEEdHTn2jWAa68bqqhsfqdfduDf9NgDAqYW3g2mum8FxiWr80XLU/Vy6uJ919rx19HD68D7tW3V2EVGyi6RCyS6SCCW7SCKU7CKJULKLJELJLpKIEsazZ9eULRhzbk5NmM785ABQrfq1y2hcdsupJ7dW/X5vccfwxzVZC2rljUZ2Hb9lfh09qumOBMcFwzU3XGnlnJje0c8x43nr8NHfdCDHs5N8hOQsyWPrbttB8mmSJzrft0fbEZFybeZt/I8A3PGR2+4H8IyZHQDwTOd3ERlgYbKb2bMALnzk5rsAHOn8fATA3T3ul4j0WLf/oJsys3MA0Pl+RdYdSR4iOUNyZnFhocvdiUheff9vvJkdNrNpM5se27Kl37sTkQzdJvt5knsAoPN9tnddEpF+6DbZnwRwT+fnewA80ZvuiEi/hHV2ko8CuB3ALpJnAHwbwEMAfkbyXgBvAPjiZndIp/xYjcY+e2POG36tuxLUm2sM6qrO/OvtoCZbr/uPazUY794MxpQPO32LHlcrGM/OYF75+rA/Fr/VzG7vzhGwCWXW2SO1mn/9gadfjytMdjM7mBH6bNRWRAaHLpcVSYSSXSQRSnaRRCjZRRKhZBdJROFDXIfq2bW3WlR684axrjT8fbf90txwxd+3V8JiUBqLlou2YBToSDBEdmLbZGasEgy1nF+45MYXlpfceCV4bBwaceP91K9hpJuJ/0kOcRWRy4OSXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEFFpnBwBzlhf2hr8CQMWpIbaitn4YQ8Ed2o3sOn5jadltOznuz9BTC+qq0XTQK06tnMFQzaFgCOvEqF8nj4aprgTXL5TlT7nO3u12dWYXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEFDuenUBt2NllUF5su2PS/Vr0UDBWnsGsxguX5jNjF2bfdtuO7LvGjW/bOuHGFxcX3fjJ11/PjDVa/jTVe6/Z58a37fAX6F1c9q8xaDtTKuedSjqPvHX0SFRnz7PvbvumM7tIIpTsIolQsoskQskukgglu0gilOwiiVCyiySi0Dp7pVrB2NhYZrzd8ucgb7Wza8aVul97HB3yl9CtNv06fcMZz37x4rtu2y3BvO9X7N7pxqOabWM1u9Z9aXHBbRstTTxU8fe9tOBvv74ze077vHX2qH2/xoX3O17avPEkHyE5S/LYutseJPkmyaOdrzuj7YhIuTbzNv5HAO7Y4Pbvmdktna+netstEem1MNnN7FkAFwroi4j0UZ5/0N1H8sXO2/zMC6hJHiI5Q3Lm0py/rpiI9E+3yf4DAJ8CcAuAcwC+k3VHMztsZtNmNj0+Od7l7kQkr66S3czOm1nLzNoAfgjg1t52S0R6ratkJ7ln3a9fAHAs674iMhjCOjvJRwHcDmAXyTMAvg3gdpK3ADAApwB8bTM7YxuoL2XXs9vwa7ptZn8MaFb92uRi2992BX6Nf+tV12fG/mrqarft7377rBtvL7/nxm++8YAbvyq7lI0zl/xtTyJ7nD4AbEHdjW8f9o/bPLJr4dWhaLJ//+kZ1dlbrex4MBV/uK59tepft2FRjd+c82zQtuJO/JC93TDZzezgBjc/HLUTkcGiy2VFEqFkF0mEkl0kEUp2kUQo2UUSUexU0qA/XNO6L1dU6b9umQVL6DolIgCoOmXBSlAyvP767LIdALz52u/d+Py8Xx6bmprKjL3+h1Nu29OnT7vxbTt3ufF63S/N5Rlm6qzuDQCwYHiuN3w3Kr0hWMo67xDXivN8DdtGc65nthORJCjZRRKhZBdJhJJdJBFKdpFEKNlFEqFkF0lEoXV2MJgWOaiz06uVe0MGEdfZg7Iqqs5wySH6h/Gaa/wlm997y691v/XWW278+v3Zyy57NXgAeG9uzo2///77bnxswhlfC6DiXL/AoNht9IfPVuEPM4X3XAtG17aDGn87uEM0/Ted82wlujbBi+eZSlpELg9KdpFEKNlFEqFkF0mEkl0kEUp2kUQo2UUSUfB49mBJ2WBMuldLt7DO7sfzjWcP6sFD/mG+4YYb3Pjxl4+68bNnz2bG9uzZkxkDgBVnKWoAuHDBX+Zvx+4r3PhwO/uxt8Iluv14VAuvevXoqv83YbTxQLQUdp46O+lcu+D1yd2qiFw2lOwiiVCyiyRCyS6SCCW7SCKU7CKJULKLJKLY8ewAnBJhOKbcWwaX4Vza+eb59jrn1UwBYHl5wY3vmvJr1ZOn/THjs7OzmbHF5SW3ba3mjwnftnWrGx8e8tuPMnte+Waz6bZdafjxdrBksyf6e1erUZ08mNs9R509nnPeedxO0/DMTnIfyV+RPE7yZZLf6Ny+g+TTJE90vm+PtiUi5dnM2/gmgG+Z2Y0A/hrA10neBOB+AM+Y2QEAz3R+F5EBFSa7mZ0zsxc6P88DOA5gL4C7ABzp3O0IgLv71UkRye8T/YOO5HUAPgPgNwCmzOwcsPaCAGDDD54kD5GcITkzP38pX29FpGubTnaS4wB+DuCbZubPUriOmR02s2kzm56YGO+mjyLSA5tKdpI1rCX6T8zsF52bz5Pc04nvAZD9L2ERKV1YeuNaHeBhAMfN7LvrQk8CuAfAQ53vT/Slh+v7kqdtVM6ISiVtp/SWc/nelZUVN7537143/spc9jDUY8eOuW1v/PSn3fj+/fvd+MqqXx6rVbKni65EyyIHQ4MbQemNXrk0ejIFQ2AtGI4drQjtT/nsd8680ptjM3X22wB8BcBLJD8YWP0A1pL8ZyTvBfAGgC921QMRKUSY7Gb2a2SfVD/b2+6ISL/oclmRRCjZRRKhZBdJhJJdJBFKdpFEFDyVNFF16tntYMlmb4hrOA118LoWTR1Mb8hjsO/ayLAbX1646MbHxsb87TvDVMdGRt22V191lRsfHR5x45fm/ammV7wlm4NrG6rV7OGxAFCp+Msit5ynU1gHD0TXZbRz7MC5pANAMEW2Q2d2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRKhZBdJROFTSVfduW6jMcL9m0oawdTBFWfJZwbXB0RLNleH/Tr84nv+dF5tp6h78803u20PHDjgxqMlm1eDsfhLq4uZsVrdr+HXRvxrHyo1v705f5d2sMx2O1jiu+0V8QGQ/jUA3lMmeiZ3W8LXmV0kEUp2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRJReJ3dvLm+g3nAvWnGg1K3O7YZ8JeSBoLaZjD/ebQ0ca3q12RPnTrlxkdGsuvN1157rdv2/Lm33Pjb7/h19kYwD8DElVdmxpaW5t22kZEhf7x7s5ldS19pB9dV1P24RWPxa92nVtuZAwAA6FxX4bXUmV0kEUp2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRKxmfXZ9wH4MYArsVZuPmxm3yf5IIB/AvB2564PmNlT4fa8QmCeBdhLFI0vfvXkSTd+3dQON7579243vrI4lxl744033LZzc9ltAWB0bNyN7949FWw/e078ZnDgRkf9Oe9HhrPnyweAqhMfavm17HbVn2OgGYx3j1ZQd8ezB42ja0qybKby3wTwLTN7geQEgOdJPt2Jfc/M/q27XYtIkTazPvs5AOc6P8+TPA5gb787JiK99Yk+s5O8DsBnAPymc9N9JF8k+QjJ7RltDpGcITkzP5/v8kgR6d6mk53kOICfA/immc0B+AGATwG4BWtn/u9s1M7MDpvZtJlNT0xM9KDLItKNTSU7yRrWEv0nZvYLADCz82bWMrM2gB8CuLV/3RSRvMJkJ0kADwM4bmbfXXf7nnV3+wKAY73vnoj0ymb+G38bgK8AeInk0c5tDwA4SPIWrFUZTgH4Wt7ORK88eZfZ9UTlDLcakrNUcvH999z4ylL2dMwA0F5dzYwtXlpw2y4u+tuuVPynyOzsrBu/uPB+Zqxa98tbtSC+dbtfkqzVsg98I/ijtILh1tGw5UrdH37riZ4v7DITNvPf+F9j4wp4WFMXkcGhK+hEEqFkF0mEkl0kEUp2kUQo2UUSoWQXSUShU0kTQMUpX+aa7rnE4bFRXXTXrl1ufH72TTd+8d133fiwc1CjenA9qAe3Wv7Sxq+/5g/fbVSyl3QeGdvitp3cuuFwiz9qriy7cTrXCHjLOQNAKyhlNxp+HX44OK7e5vt1BtaZXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEkF3CeVe74x8G8Af1t20C8A7hXXgkxnUvg1qvwD1rVu97Nu1ZrbhQP9Ck/1jOydnzGy6tA44BrVvg9ovQH3rVlF909t4kUQo2UUSUXayHy55/55B7dug9gtQ37pVSN9K/cwuIsUp+8wuIgVRsoskopRkJ3kHyVdIvkry/jL6kIXkKZIvkTxKcqbkvjxCcpbksXW37SD5NMkTne/+oO9i+/YgyTc7x+4oyTtL6ts+kr8ieZzkyyS/0bm91GPn9KuQ41b4Z3aSVQD/B+DvAZwB8ByAg2b2v4V2JAPJUwCmzaz0CzBI/i2ASwB+bGZ/3rntXwFcMLOHOi+U283snwekbw8CuFT2Mt6d1Yr2rF9mHMDdAL6KEo+d069/QAHHrYwz+60AXjWzk2a2CuCnAO4qoR8Dz8yeBXDhIzffBeBI5+cjWHuyFC6jbwPBzM6Z2Qudn+cBfLDMeKnHzulXIcpI9r0ATq/7/QwGa713A/BLks+TPFR2ZzYwZWbngLUnD4ArSu7PR4XLeBfpI8uMD8yx62b587zKSPaNJv8apPrfbWb2lwA+D+DrnbersjmbWsa7KBssMz4Qul3+PK8ykv0MgH3rfr8awNkS+rEhMzvb+T4L4HEM3lLU5z9YQbfz3V9ZsUCDtIz3RsuMYwCOXZnLn5eR7M8BOEByP8k6gC8BeLKEfnwMyS2df5yA5BYAn8PgLUX9JIB7Oj/fA+CJEvvyIYOyjHfWMuMo+diVvvy5mRX+BeBOrP1H/jUA/1JGHzL6dT2A33W+Xi67bwAexdrbugbW3hHdC2AngGcAnOh83zFAfftPAC8BeBFribWnpL79DdY+Gr4I4Gjn686yj53Tr0KOmy6XFUmErqATSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFE/D9Q9xpAOOV0nAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/my_rsp_full/my_rsp_final/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_train_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 2.7617 - accuracy: 0.5181\n",
      "Epoch 2/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.7145\n",
      "Epoch 3/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7842\n",
      "Epoch 4/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8453\n",
      "Epoch 5/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8723\n",
      "Epoch 6/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.9012\n",
      "Epoch 7/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9229\n",
      "Epoch 8/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9351\n",
      "Epoch 9/15\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9507\n",
      "Epoch 10/15\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9431\n",
      "Epoch 11/15\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9673\n",
      "Epoch 12/15\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9722\n",
      "Epoch 13/15\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9819\n",
      "Epoch 14/15\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9839\n",
      "Epoch 15/15\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9837\n",
      "10/10 - 0s - loss: 1.8336 - accuracy: 0.6533\n",
      "test_loss: 1.833574652671814 \n",
      "test_accuracy: 0.653333306312561\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 3,799,626\n",
      "Trainable params: 3,799,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#VGGNET\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), input_shape=(28,28,3), activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64,(3,3),padding = 'same', activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), padding = 'valid', activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Dense(256, activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(rate = 0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "123/123 [==============================] - 7s 59ms/step - loss: 3.5181 - accuracy: 0.3608\n",
      "Epoch 2/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.9318 - accuracy: 0.5730\n",
      "Epoch 3/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6650 - accuracy: 0.7245\n",
      "Epoch 4/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.5139 - accuracy: 0.7896\n",
      "Epoch 5/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.4331 - accuracy: 0.8253\n",
      "Epoch 6/25\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.8680\n",
      "Epoch 7/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3176 - accuracy: 0.8833\n",
      "Epoch 8/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3019 - accuracy: 0.8894\n",
      "Epoch 9/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2551 - accuracy: 0.9060\n",
      "Epoch 10/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2331 - accuracy: 0.9168\n",
      "Epoch 11/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2385 - accuracy: 0.9142\n",
      "Epoch 12/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9346\n",
      "Epoch 13/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1693 - accuracy: 0.9390\n",
      "Epoch 14/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1305 - accuracy: 0.9535\n",
      "Epoch 15/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1722 - accuracy: 0.9377\n",
      "Epoch 16/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1235 - accuracy: 0.9535\n",
      "Epoch 17/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9405\n",
      "Epoch 18/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1232 - accuracy: 0.9535\n",
      "Epoch 19/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1360 - accuracy: 0.9589\n",
      "Epoch 20/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9614\n",
      "Epoch 21/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1154 - accuracy: 0.9602\n",
      "Epoch 22/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1294 - accuracy: 0.9604\n",
      "Epoch 23/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9729\n",
      "Epoch 24/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9709\n",
      "Epoch 25/25\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0986 - accuracy: 0.9665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9213d6250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,  y_train, epochs= 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.35517045855522156 \n",
      "test_accuracy: 0.8500000238418579\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=3)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이번 가위바위보 프로젝트하면서 느낀 건 딱 한가지이다. 바로 '데이터의 중요성'이다. 처음엔 내가 찍은 300개 갖고 아둥바둥했고 처음엔 노이즈가 많이 껴서 그렇다고 생각했다. 그래서 다시 깔끔하게 300개를 찍어서 다시 했다. 깔끔하다보니 노이즈가 적어 정확도가 좋아졌다고 생각했지만 정확도가 안정적이지 못했다. 그다음 내가 생각해 낸것은 모델이었다. 모델이 별로라서 VGGNet을 이용해서 테스트해봤지만 정확도가 조금 좋아졌을뿐 안정성에서는 꽝이었다.   \n",
    "### 나중엔 자포자기로 한번 슬랙에 들어와 있는 모든 학생의 손 3912개를 가져와서 시도했다. 결과는 안정적인 정확도가 나왔다. 여기서 딥러닝을 위해 가장 중요한 건 풍부한 데이터셋이고 풍부한 데이터셋이 보장되지 않는 한 좋은 모델이나 좋은 데이터는 의미가 없다는 것을 느꼈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
