{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face2Imogi 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35887/35887 [00:26<00:00, 1349.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 32298, eval :3589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "eval_x = []\n",
    "eval_y = []\n",
    "\n",
    "csv_path = os.getenv('HOME')+'/aiffel/tfjs_mobile/data/fer2013.csv'\n",
    "\n",
    "with open(csv_path) as f:\n",
    "  for line in tqdm.tqdm(f.read().splitlines()[1:]):\n",
    "    emotion, pixels, usage = line.split(',')\n",
    "    \n",
    "    x = np.array(pixels.split(' ')).astype(float).reshape(48, 48, 1) / 255\n",
    "    y = int(emotion)\n",
    "\n",
    "    if usage == 'PrivateTest':\n",
    "      eval_x.append(x)\n",
    "      eval_y.append(y)\n",
    "    else:\n",
    "      train_x.append(x)\n",
    "      train_y.append(y)\n",
    "\n",
    "print('train : {}, eval :{}'.format(len(train_x), len(eval_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd13c1ae90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "LABELS = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "print(LABELS[train_y[0]])\n",
    "plt.imshow(train_x[0].reshape([48, 48]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MobileNet으로 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 72s 1s/step - loss: 1.8259 - categorical_accuracy: 0.2532 - val_loss: 1.9330 - val_categorical_accuracy: 0.2449\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.6757 - categorical_accuracy: 0.3316 - val_loss: 1.9239 - val_categorical_accuracy: 0.2449\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 6s 92ms/step - loss: 1.5477 - categorical_accuracy: 0.3973 - val_loss: 1.9218 - val_categorical_accuracy: 0.1471\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.4691 - categorical_accuracy: 0.4327 - val_loss: 1.9191 - val_categorical_accuracy: 0.1471\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.3899 - categorical_accuracy: 0.4691 - val_loss: 1.9211 - val_categorical_accuracy: 0.1471\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.3390 - categorical_accuracy: 0.4872 - val_loss: 1.9201 - val_categorical_accuracy: 0.1744\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.2685 - categorical_accuracy: 0.5174 - val_loss: 1.9150 - val_categorical_accuracy: 0.1744\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.1906 - categorical_accuracy: 0.5530 - val_loss: 1.9151 - val_categorical_accuracy: 0.1744\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.1542 - categorical_accuracy: 0.5658 - val_loss: 1.9091 - val_categorical_accuracy: 0.1655\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 6s 93ms/step - loss: 1.0894 - categorical_accuracy: 0.5918 - val_loss: 1.9034 - val_categorical_accuracy: 0.1655\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 1.0102 - categorical_accuracy: 0.6301 - val_loss: 1.9062 - val_categorical_accuracy: 0.1655\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 6s 94ms/step - loss: 0.9755 - categorical_accuracy: 0.6405 - val_loss: 1.8959 - val_categorical_accuracy: 0.1655\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.9538 - categorical_accuracy: 0.6506 - val_loss: 1.8989 - val_categorical_accuracy: 0.1655\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 6s 101ms/step - loss: 0.9015 - categorical_accuracy: 0.6700 - val_loss: 1.8888 - val_categorical_accuracy: 0.1655\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 0.8195 - categorical_accuracy: 0.7013 - val_loss: 1.8933 - val_categorical_accuracy: 0.1655\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.7651 - categorical_accuracy: 0.7217 - val_loss: 1.8972 - val_categorical_accuracy: 0.1655\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.7189 - categorical_accuracy: 0.7394 - val_loss: 1.8974 - val_categorical_accuracy: 0.1655\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 6s 101ms/step - loss: 0.6761 - categorical_accuracy: 0.7567 - val_loss: 1.8996 - val_categorical_accuracy: 0.1655\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 0.6107 - categorical_accuracy: 0.7816 - val_loss: 1.9105 - val_categorical_accuracy: 0.1655\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 0.6164 - categorical_accuracy: 0.7765 - val_loss: 1.9136 - val_categorical_accuracy: 0.1655\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 7s 102ms/step - loss: 0.5362 - categorical_accuracy: 0.8062 - val_loss: 1.9204 - val_categorical_accuracy: 0.1655\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 6s 100ms/step - loss: 0.5419 - categorical_accuracy: 0.8035 - val_loss: 1.9170 - val_categorical_accuracy: 0.1655\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 6s 101ms/step - loss: 0.4634 - categorical_accuracy: 0.8342 - val_loss: 1.9369 - val_categorical_accuracy: 0.1655\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.4915 - categorical_accuracy: 0.8230 - val_loss: 1.9529 - val_categorical_accuracy: 0.1655\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.4214 - categorical_accuracy: 0.8480 - val_loss: 1.9508 - val_categorical_accuracy: 0.1655\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.4112 - categorical_accuracy: 0.8511 - val_loss: 1.9696 - val_categorical_accuracy: 0.1655\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.4621 - categorical_accuracy: 0.8340 - val_loss: 1.9764 - val_categorical_accuracy: 0.1655\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.3601 - categorical_accuracy: 0.8705 - val_loss: 1.9896 - val_categorical_accuracy: 0.1655\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.3289 - categorical_accuracy: 0.8829 - val_loss: 1.9966 - val_categorical_accuracy: 0.1655\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.3645 - categorical_accuracy: 0.8709 - val_loss: 1.9891 - val_categorical_accuracy: 0.1655\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.3427 - categorical_accuracy: 0.8775 - val_loss: 2.0206 - val_categorical_accuracy: 0.1655\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.2876 - categorical_accuracy: 0.8973 - val_loss: 2.0319 - val_categorical_accuracy: 0.1655\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2670 - categorical_accuracy: 0.9049 - val_loss: 2.0773 - val_categorical_accuracy: 0.1655\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2548 - categorical_accuracy: 0.9117 - val_loss: 2.1038 - val_categorical_accuracy: 0.1655\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2133 - categorical_accuracy: 0.9263 - val_loss: 2.0952 - val_categorical_accuracy: 0.1655\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.2859 - categorical_accuracy: 0.8981 - val_loss: 2.0790 - val_categorical_accuracy: 0.1655\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.2112 - categorical_accuracy: 0.9269 - val_loss: 2.0760 - val_categorical_accuracy: 0.1655\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2478 - categorical_accuracy: 0.9135 - val_loss: 2.0954 - val_categorical_accuracy: 0.1655\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2126 - categorical_accuracy: 0.9260 - val_loss: 2.1213 - val_categorical_accuracy: 0.1655\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2429 - categorical_accuracy: 0.9145 - val_loss: 2.1225 - val_categorical_accuracy: 0.1655\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.2101 - categorical_accuracy: 0.9259 - val_loss: 2.1075 - val_categorical_accuracy: 0.1655\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1666 - categorical_accuracy: 0.9422 - val_loss: 2.1070 - val_categorical_accuracy: 0.1655\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1720 - categorical_accuracy: 0.9398 - val_loss: 2.1266 - val_categorical_accuracy: 0.1655\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1478 - categorical_accuracy: 0.9482 - val_loss: 2.1433 - val_categorical_accuracy: 0.1655\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.2044 - categorical_accuracy: 0.9286 - val_loss: 2.1659 - val_categorical_accuracy: 0.1655\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1614 - categorical_accuracy: 0.9450 - val_loss: 2.2155 - val_categorical_accuracy: 0.1655\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.3269 - categorical_accuracy: 0.8857 - val_loss: 2.2113 - val_categorical_accuracy: 0.1655\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.2217 - categorical_accuracy: 0.9207 - val_loss: 2.2329 - val_categorical_accuracy: 0.1655\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1933 - categorical_accuracy: 0.9328 - val_loss: 2.2357 - val_categorical_accuracy: 0.1655\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1959 - categorical_accuracy: 0.9323 - val_loss: 2.2922 - val_categorical_accuracy: 0.1655\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1455 - categorical_accuracy: 0.9501 - val_loss: 2.3336 - val_categorical_accuracy: 0.1655\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1414 - categorical_accuracy: 0.9519 - val_loss: 2.3473 - val_categorical_accuracy: 0.1655\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.2239 - categorical_accuracy: 0.9205 - val_loss: 2.4264 - val_categorical_accuracy: 0.1655\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1607 - categorical_accuracy: 0.9443 - val_loss: 2.4373 - val_categorical_accuracy: 0.1655\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.0926 - categorical_accuracy: 0.9693 - val_loss: 2.5150 - val_categorical_accuracy: 0.1655\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2391 - categorical_accuracy: 0.9183 - val_loss: 2.3857 - val_categorical_accuracy: 0.1655\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1228 - categorical_accuracy: 0.9579 - val_loss: 2.5786 - val_categorical_accuracy: 0.1655\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1785 - categorical_accuracy: 0.9364 - val_loss: 2.6094 - val_categorical_accuracy: 0.1655\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1324 - categorical_accuracy: 0.9546 - val_loss: 2.4859 - val_categorical_accuracy: 0.1655\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1309 - categorical_accuracy: 0.9548 - val_loss: 2.7336 - val_categorical_accuracy: 0.1655\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1134 - categorical_accuracy: 0.9623 - val_loss: 2.9618 - val_categorical_accuracy: 0.1655\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1774 - categorical_accuracy: 0.9392 - val_loss: 2.3987 - val_categorical_accuracy: 0.1658\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1389 - categorical_accuracy: 0.9516 - val_loss: 2.5241 - val_categorical_accuracy: 0.1655\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1130 - categorical_accuracy: 0.9604 - val_loss: 2.7425 - val_categorical_accuracy: 0.1655\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1193 - categorical_accuracy: 0.9589 - val_loss: 2.7553 - val_categorical_accuracy: 0.1728\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1386 - categorical_accuracy: 0.9511 - val_loss: 2.3842 - val_categorical_accuracy: 0.2179\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1108 - categorical_accuracy: 0.9615 - val_loss: 2.7355 - val_categorical_accuracy: 0.1875\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.1471 - categorical_accuracy: 0.9498 - val_loss: 2.6422 - val_categorical_accuracy: 0.2327\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1211 - categorical_accuracy: 0.9582 - val_loss: 2.5381 - val_categorical_accuracy: 0.2694\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1034 - categorical_accuracy: 0.9646 - val_loss: 2.6462 - val_categorical_accuracy: 0.2639\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1021 - categorical_accuracy: 0.9649 - val_loss: 2.7415 - val_categorical_accuracy: 0.2862\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0909 - categorical_accuracy: 0.9689 - val_loss: 3.0305 - val_categorical_accuracy: 0.2474\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.2643 - categorical_accuracy: 0.9077 - val_loss: 3.0463 - val_categorical_accuracy: 0.2948\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1330 - categorical_accuracy: 0.9538 - val_loss: 3.0477 - val_categorical_accuracy: 0.3006\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1576 - categorical_accuracy: 0.9465 - val_loss: 3.1442 - val_categorical_accuracy: 0.3107\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.1211 - categorical_accuracy: 0.9590 - val_loss: 2.8067 - val_categorical_accuracy: 0.3502\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1614 - categorical_accuracy: 0.9432 - val_loss: 3.1597 - val_categorical_accuracy: 0.3452\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1029 - categorical_accuracy: 0.9656 - val_loss: 3.0736 - val_categorical_accuracy: 0.3491\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0974 - categorical_accuracy: 0.9667 - val_loss: 2.8276 - val_categorical_accuracy: 0.3801\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1023 - categorical_accuracy: 0.9650 - val_loss: 3.2588 - val_categorical_accuracy: 0.3625\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0914 - categorical_accuracy: 0.9694 - val_loss: 3.1251 - val_categorical_accuracy: 0.3915\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0996 - categorical_accuracy: 0.9663 - val_loss: 3.5357 - val_categorical_accuracy: 0.3904\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 6s 99ms/step - loss: 0.1069 - categorical_accuracy: 0.9640 - val_loss: 3.3994 - val_categorical_accuracy: 0.4062\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0978 - categorical_accuracy: 0.9651 - val_loss: 3.5859 - val_categorical_accuracy: 0.4218\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.1204 - categorical_accuracy: 0.9576 - val_loss: 3.5189 - val_categorical_accuracy: 0.4310\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1285 - categorical_accuracy: 0.9553 - val_loss: 3.4362 - val_categorical_accuracy: 0.4316\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1153 - categorical_accuracy: 0.9615 - val_loss: 3.7248 - val_categorical_accuracy: 0.4235\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.2194 - categorical_accuracy: 0.9238 - val_loss: 3.8687 - val_categorical_accuracy: 0.4425\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1148 - categorical_accuracy: 0.9607 - val_loss: 3.9825 - val_categorical_accuracy: 0.4358\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1737 - categorical_accuracy: 0.9407 - val_loss: 4.3474 - val_categorical_accuracy: 0.4444\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0753 - categorical_accuracy: 0.9742 - val_loss: 4.7188 - val_categorical_accuracy: 0.4269\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1078 - categorical_accuracy: 0.9625 - val_loss: 4.5639 - val_categorical_accuracy: 0.4333\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.0925 - categorical_accuracy: 0.9683 - val_loss: 4.4193 - val_categorical_accuracy: 0.4391\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.0865 - categorical_accuracy: 0.9698 - val_loss: 4.5213 - val_categorical_accuracy: 0.4349\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 6s 98ms/step - loss: 0.1315 - categorical_accuracy: 0.9547 - val_loss: 4.5541 - val_categorical_accuracy: 0.4257\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.1152 - categorical_accuracy: 0.9597 - val_loss: 4.6374 - val_categorical_accuracy: 0.4140\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.0869 - categorical_accuracy: 0.9696 - val_loss: 4.9117 - val_categorical_accuracy: 0.3973\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0730 - categorical_accuracy: 0.9746 - val_loss: 4.8895 - val_categorical_accuracy: 0.4319\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 6s 96ms/step - loss: 0.0873 - categorical_accuracy: 0.9700 - val_loss: 4.8708 - val_categorical_accuracy: 0.4035\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 6s 97ms/step - loss: 0.0966 - categorical_accuracy: 0.9662 - val_loss: 4.7710 - val_categorical_accuracy: 0.4335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc3c0f7e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# model 선언 \n",
    "model = tf.keras.applications.MobileNetV2(input_shape=(48, 48, 1), weights=None, classes=7)\n",
    "\n",
    "# model.compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "#model.fit\n",
    "model.fit(np.stack(train_x),\n",
    "          tf.keras.utils.to_categorical(train_y),\n",
    "          epochs=100,\n",
    "          batch_size=512,\n",
    "          validation_data=(np.stack(eval_x),\n",
    "                           tf.keras.utils.to_categorical(eval_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_path = os.getenv('HOME')+'/aiffel/tfjs_mobile/model.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. index.html 만들고 Github에 올리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, user-scalable=yes, initial-scale=1, maximum-scale=1\">\n",
    "    <title>Demo</title>\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.1\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <video playsinline autoplay></video>\n",
    "    <button>Capture</button>\n",
    "    <canvas></canvas>\n",
    "    <span></span>\n",
    "    <script>\n",
    "      video = document.querySelector('video');\n",
    "      canvas = document.querySelector('canvas');\n",
    "      button = document.querySelector('button');\n",
    "      canvas.width = 48;\n",
    "      canvas.height = 48;\n",
    "      canvas.style.filter = 'grayscale(1)';\n",
    "      video.style.transform = 'scaleX(-1)';\n",
    "\n",
    "      span = document.querySelector('span');\n",
    "      span.style.fontSize = '48px';\n",
    "\n",
    "\n",
    "      const LABELS = {\n",
    "        0: '🤬', // angry\n",
    "        1: '🤢', // disgust\n",
    "        2: '😱', // fear\n",
    "        3: '😄', // happy\n",
    "        4: '😢', // sad\n",
    "        5: '😲', // surprise\n",
    "        6: '😐' // neutral\n",
    "      }\n",
    "      \n",
    "      function classifyCallback(predictions) {\n",
    "        alert(predictions[0].className + ':' + predictions[0].probabaility);\n",
    "      }\n",
    "\n",
    "      async function predict() {\n",
    "        const model = await tf.loadLayersModel('./model/model.json');\n",
    "\n",
    "        image = tf.browser.fromPixels(canvas);\n",
    "        console.log(image);\n",
    "        image = image.toFloat().mean(2).mul(1/255.0).reshape([-1, 48, 48, 1]);\n",
    "        logits = model.predict(image);\n",
    "        const results = await logits.softmax().data();\n",
    "        i = results.indexOf(Math.max(...results));\n",
    "\n",
    "        image.dispose();\n",
    "        logits.dispose();\n",
    "        console.log(results);\n",
    "        \n",
    "        span.innerHTML = LABELS[i];\n",
    "      }\n",
    "\n",
    "      button.onclick = function() {\n",
    "        w = video.videoWidth;\n",
    "        h = video.videoHeight;\n",
    "        s = Math.min(w, h);\n",
    "        sx = (w-s)/2;\n",
    "        sy = (h-s)/2;\n",
    "\n",
    "        canvas.getContext('2d').drawImage(video, sx=sx, sy=sy, swidth=s,\n",
    "          sheight=s, x=0, y=0, width=48, height=48);\n",
    "\n",
    "        span.innerHTML = '⌛';\n",
    "        predict();\n",
    "    };\n",
    "\n",
    "\n",
    "    constraints = {\n",
    "      audio: false,\n",
    "      video: true\n",
    "    };\n",
    "\n",
    "    function handleSuccess(stream) {\n",
    "      video.srcObject = stream;\n",
    "    }\n",
    "\n",
    "    function handleError(error) {\n",
    "      alert('navigator.MediaDevices.getUserMedia error: ' + error.message + error.name);\n",
    "    }\n",
    "\n",
    "    navigator.mediaDevices.getUserMedia(constraints).then(handleSuccess).catch(handleError);\n",
    "    </script>\n",
    "</body>\n",
    "\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 완성품"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mezcalagave.github.io/tfjs_mobile/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 개선할 수 있는 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 과거에 배웠던 face recognition을 이용하는 방법도 하나일 것이다.    \n",
    "2. transfer learning이 가능했다면 더 좋았을 수도 있다.    \n",
    "3. 데이터가 많으면 더 정확해질 가능성이 있다.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 느낀점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선적으로 처음 javascript와 html을 전문적으로 쓰다 보니 이번 노드를 하는데 애를 먹었다. 그러나 모바일로 딥러닝을 구현해냈다는 점에서 매우 신기했다.     \n",
    "그러나 모바일에서 구현한다는 것 자체가 아무래도 한계점은 노출시키고 있다고 생각한다. 혹자는 딥러닝이 발전한 이유는 여러 학자들의 공헌이라고 얘기하기보다 GPU라는 하드웨어의 발달에 맞춰 진화한 것이라고 이야기한다.    이에 대해 어느정도 동의한다. 그러나 인간이 AI를 더 경량화하여 어디에든 장착할 수 있다고 가정하면 많은 활용성을 가져다 줄 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
