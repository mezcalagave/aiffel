{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# babi QA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.getenv('HOME') + '/aiffel/babi_memory_net/data/qa1_single-supporting-fact_train_kor.txt'\n",
    "test_path = os.getenv('HOME') + '/aiffel/babi_memory_net/data/qa1_single-supporting-fact_test_kor.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n",
      "2 은경이는 복도로 이동했습니다.\n",
      "3 필웅이는 어디야? \t화장실\t1\n",
      "4 수종이는 복도로 복귀했습니다.\n",
      "5 경임이는 정원으로 갔습니다.\n",
      "6 수종이는 어디야? \t복도\t4\n",
      "7 은경이는 사무실로 갔습니다.\n",
      "8 경임이는 화장실로 뛰어갔습니다.\n",
      "9 수종이는 어디야? \t복도\t4\n",
      "10 필웅이는 복도로 갔습니다.\n",
      "11 수종이는 사무실로 가버렸습니다.\n",
      "12 수종이는 어디야? \t사무실\t11\n",
      "13 은경이는 정원으로 복귀했습니다.\n",
      "14 은경이는 침실로 갔습니다.\n",
      "15 경임이는 어디야? \t화장실\t8\n",
      "1 경임이는 사무실로 가버렸습니다.\n",
      "2 경임이는 화장실로 이동했습니다.\n",
      "3 경임이는 어디야? \t화장실\t2\n",
      "4 필웅이는 침실로 이동했습니다.\n",
      "5 수종이는 복도로 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(train_path , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(train_path)\n",
    "test_data = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(train_path)\n",
    "test_stories, test_questions, test_answers = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_stories))\n",
    "print(len(train_questions))\n",
    "print(len(train_answers))\n",
    "print(len(test_stories))\n",
    "print(len(test_questions))\n",
    "print(len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['수종이는 화장실로 뛰어갔습니다.',\n",
       " '경임이는 사무실로 갔습니다.',\n",
       " '은경이는 부엌으로 이동했습니다.',\n",
       " '경임이는 화장실로 갔습니다.',\n",
       " '수종이는 복도로 갔습니다.',\n",
       " '필웅이는 부엌으로 가버렸습니다.',\n",
       " '수종이는 부엌으로 이동했습니다.',\n",
       " '수종이는 화장실로 가버렸습니다.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['경임이는 화장실로 복귀했습니다.', '필웅이는 정원으로 갔습니다.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['필웅이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '경임이는 어디야? ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화장실', '복도', '복도', '사무실', '화장실']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Customized_konlpy 이용해 이름을 사전에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0038/anaconda3/envs/aiffel/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('수종이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Noun')\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('필웅이', 'Noun')\n",
    "def tokenize(sent):\n",
    "    return twitter.morphs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['은경이', '는', '화장실', '로', '이동', '했습니다', '.']\n",
      "['경임이', '는', '정원', '으로', '가버렸습니다', '.']\n",
      "['수종이', '는', '복도', '로', '뛰어갔습니다', '.']\n",
      "['필웅이', '는', '부엌', '으로', '복귀', '했습니다', '.']\n",
      "['수종이', '는', '사무실', '로', '갔습니다', '.']\n",
      "['은경이', '는', '침실', '로', '갔습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(twitter.morphs('은경이는 화장실로 이동했습니다.'))\n",
    "print(twitter.morphs('경임이는 정원으로 가버렸습니다.'))\n",
    "print(twitter.morphs('수종이는 복도로 뛰어갔습니다.'))\n",
    "print(twitter.morphs('필웅이는 부엌으로 복귀했습니다.'))\n",
    "print(twitter.morphs('수종이는 사무실로 갔습니다.'))\n",
    "print(twitter.morphs('은경이는 침실로 갔습니다.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'는': 1, '.': 2, '로': 3, '했습니다': 4, '으로': 5, '경임이': 6, '은경이': 7, '수종이': 8, '필웅이': 9, '이동': 10, '가버렸습니다': 11, '뛰어갔습니다': 12, '복귀': 13, '화장실': 14, '정원': 15, '복도': 16, '갔습니다': 17, '사무실': 18, '부엌': 19, '침실': 20, '어디': 21, '야': 22, '?': 23}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 70\n",
      "질문의 최대 길이 : 5\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 토큰화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 70) (10000, 5) (10000, 24) (1000, 70) (1000, 5) (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. End-to-End memory Network 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : Tensor(\"input_1:0\", shape=(None, 70), dtype=float32)\n",
      "Question: Tensor(\"input_2:0\", shape=(None, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m Tensor(\"sequential/Identity:0\", shape=(None, 70, 50), dtype=float32)\n",
      "Input encoded c Tensor(\"sequential_1/Identity:0\", shape=(None, 70, 5), dtype=float32)\n",
      "Question encoded Tensor(\"sequential_2/Identity:0\", shape=(None, 5, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape Tensor(\"activation/Identity:0\", shape=(None, 70, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response shape Tensor(\"permute/Identity:0\", shape=(None, 5, 70), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer shape Tensor(\"concatenate/Identity:0\", shape=(None, 5, 120), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         multiple             1200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 5, 50)        1200        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 70, 5)        0           sequential[1][0]                 \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 70, 5)        0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             120         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 70, 5)        0           activation[0][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 5, 70)        0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 120)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           47360       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           1560        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 24)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 51,440\n",
      "Trainable params: 51,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.9018 - acc: 0.1674 - val_loss: 1.8019 - val_acc: 0.1520\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.7234 - acc: 0.2478 - val_loss: 1.5822 - val_acc: 0.3870\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5425 - acc: 0.3795 - val_loss: 1.4976 - val_acc: 0.4030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5005 - acc: 0.4123 - val_loss: 1.4721 - val_acc: 0.4320\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4596 - acc: 0.4362 - val_loss: 1.4194 - val_acc: 0.4620\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4006 - acc: 0.4655 - val_loss: 1.3450 - val_acc: 0.4940\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3594 - acc: 0.4666 - val_loss: 1.3484 - val_acc: 0.4700\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3428 - acc: 0.4776 - val_loss: 1.3292 - val_acc: 0.4750\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3226 - acc: 0.4872 - val_loss: 1.2819 - val_acc: 0.5060\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2997 - acc: 0.5010 - val_loss: 1.2871 - val_acc: 0.5040\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2631 - acc: 0.5147 - val_loss: 1.2350 - val_acc: 0.5150\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2393 - acc: 0.5069 - val_loss: 1.2091 - val_acc: 0.5310\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2228 - acc: 0.5111 - val_loss: 1.2055 - val_acc: 0.5230\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2033 - acc: 0.5183 - val_loss: 1.1941 - val_acc: 0.5220\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1816 - acc: 0.5280 - val_loss: 1.2030 - val_acc: 0.5220\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1776 - acc: 0.5208 - val_loss: 1.1880 - val_acc: 0.5300\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1660 - acc: 0.5249 - val_loss: 1.1814 - val_acc: 0.5210\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1537 - acc: 0.5258 - val_loss: 1.1991 - val_acc: 0.5040\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1459 - acc: 0.5246 - val_loss: 1.1677 - val_acc: 0.5190\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1429 - acc: 0.5277 - val_loss: 1.1681 - val_acc: 0.5180\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1187 - acc: 0.5306 - val_loss: 1.1770 - val_acc: 0.5110\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1184 - acc: 0.5358 - val_loss: 1.1705 - val_acc: 0.5250\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1092 - acc: 0.5317 - val_loss: 1.1554 - val_acc: 0.5200\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1032 - acc: 0.5359 - val_loss: 1.1546 - val_acc: 0.5220\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0855 - acc: 0.5489 - val_loss: 1.1628 - val_acc: 0.5230\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0831 - acc: 0.5419 - val_loss: 1.1564 - val_acc: 0.5180\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0767 - acc: 0.5356 - val_loss: 1.1654 - val_acc: 0.5210\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0682 - acc: 0.5460 - val_loss: 1.1623 - val_acc: 0.5220\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0551 - acc: 0.5522 - val_loss: 1.1477 - val_acc: 0.5210\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0594 - acc: 0.5528 - val_loss: 1.1385 - val_acc: 0.5140\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0350 - acc: 0.5571 - val_loss: 1.1844 - val_acc: 0.5090\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0358 - acc: 0.5505 - val_loss: 1.1652 - val_acc: 0.5270\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0287 - acc: 0.5591 - val_loss: 1.1677 - val_acc: 0.5250\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0131 - acc: 0.5696 - val_loss: 1.1793 - val_acc: 0.5210\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9993 - acc: 0.5739 - val_loss: 1.1759 - val_acc: 0.5040\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9965 - acc: 0.5789 - val_loss: 1.1502 - val_acc: 0.5230\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9719 - acc: 0.5920 - val_loss: 1.1403 - val_acc: 0.5390\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9274 - acc: 0.6206 - val_loss: 1.1021 - val_acc: 0.5860\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8698 - acc: 0.6609 - val_loss: 0.9868 - val_acc: 0.6410\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.7692 - acc: 0.7036 - val_loss: 0.8617 - val_acc: 0.6920\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6909 - acc: 0.7387 - val_loss: 0.7787 - val_acc: 0.7110\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6254 - acc: 0.7592 - val_loss: 0.7185 - val_acc: 0.7340\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5826 - acc: 0.7789 - val_loss: 0.6824 - val_acc: 0.7380\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5535 - acc: 0.7922 - val_loss: 0.6611 - val_acc: 0.7450\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5213 - acc: 0.7982 - val_loss: 0.6344 - val_acc: 0.7490\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4983 - acc: 0.8023 - val_loss: 0.6092 - val_acc: 0.7460\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4699 - acc: 0.8181 - val_loss: 0.5862 - val_acc: 0.7650\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4409 - acc: 0.8277 - val_loss: 0.5602 - val_acc: 0.7750\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4197 - acc: 0.8370 - val_loss: 0.5356 - val_acc: 0.7930\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3940 - acc: 0.8498 - val_loss: 0.5273 - val_acc: 0.8070\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3649 - acc: 0.8624 - val_loss: 0.4883 - val_acc: 0.8250\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3352 - acc: 0.8745 - val_loss: 0.4717 - val_acc: 0.8330\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3245 - acc: 0.8750 - val_loss: 0.4432 - val_acc: 0.8330\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3083 - acc: 0.8850 - val_loss: 0.4177 - val_acc: 0.8420\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2868 - acc: 0.8939 - val_loss: 0.4050 - val_acc: 0.8480\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2759 - acc: 0.8987 - val_loss: 0.4212 - val_acc: 0.8440\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2580 - acc: 0.9025 - val_loss: 0.3834 - val_acc: 0.8530\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2481 - acc: 0.9090 - val_loss: 0.4059 - val_acc: 0.8590\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2382 - acc: 0.9109 - val_loss: 0.3818 - val_acc: 0.8540\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2212 - acc: 0.9202 - val_loss: 0.4347 - val_acc: 0.8490\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2027 - acc: 0.9268 - val_loss: 0.4202 - val_acc: 0.8570\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1999 - acc: 0.9271 - val_loss: 0.3859 - val_acc: 0.8650\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1918 - acc: 0.9306 - val_loss: 0.4353 - val_acc: 0.8660\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1840 - acc: 0.9337 - val_loss: 0.3714 - val_acc: 0.8650\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1736 - acc: 0.9370 - val_loss: 0.3534 - val_acc: 0.8670\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1581 - acc: 0.9429 - val_loss: 0.3579 - val_acc: 0.8780\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1569 - acc: 0.9438 - val_loss: 0.3743 - val_acc: 0.8760\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1442 - acc: 0.9480 - val_loss: 0.3555 - val_acc: 0.8830\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1416 - acc: 0.9499 - val_loss: 0.3448 - val_acc: 0.8960\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1250 - acc: 0.9553 - val_loss: 0.3315 - val_acc: 0.8980\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1263 - acc: 0.9549 - val_loss: 0.3134 - val_acc: 0.9000\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1205 - acc: 0.9582 - val_loss: 0.3196 - val_acc: 0.9000\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1159 - acc: 0.9592 - val_loss: 0.3125 - val_acc: 0.9080\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1032 - acc: 0.9646 - val_loss: 0.2996 - val_acc: 0.9180\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1057 - acc: 0.9637 - val_loss: 0.2958 - val_acc: 0.9070\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0981 - acc: 0.9652 - val_loss: 0.3569 - val_acc: 0.8990\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0956 - acc: 0.9665 - val_loss: 0.2972 - val_acc: 0.9150\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0944 - acc: 0.9683 - val_loss: 0.3371 - val_acc: 0.9090\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0835 - acc: 0.9721 - val_loss: 0.2909 - val_acc: 0.9230\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0784 - acc: 0.9712 - val_loss: 0.3079 - val_acc: 0.9100\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0823 - acc: 0.9729 - val_loss: 0.2756 - val_acc: 0.9260\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0833 - acc: 0.9716 - val_loss: 0.3014 - val_acc: 0.9200\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0676 - acc: 0.9769 - val_loss: 0.3123 - val_acc: 0.9190\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0747 - acc: 0.9749 - val_loss: 0.2967 - val_acc: 0.9120\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0607 - acc: 0.9796 - val_loss: 0.3245 - val_acc: 0.9190\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0698 - acc: 0.9771 - val_loss: 0.3445 - val_acc: 0.9130\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0569 - acc: 0.9809 - val_loss: 0.3031 - val_acc: 0.9310\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0624 - acc: 0.9779 - val_loss: 0.3296 - val_acc: 0.9160\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0596 - acc: 0.9809 - val_loss: 0.3631 - val_acc: 0.9090\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0516 - acc: 0.9813 - val_loss: 0.3360 - val_acc: 0.9240\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0560 - acc: 0.9808 - val_loss: 0.3013 - val_acc: 0.9310\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0515 - acc: 0.9832 - val_loss: 0.3154 - val_acc: 0.9270\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0533 - acc: 0.9825 - val_loss: 0.3137 - val_acc: 0.9260\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0520 - acc: 0.9829 - val_loss: 0.3315 - val_acc: 0.9220\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0474 - acc: 0.9847 - val_loss: 0.2674 - val_acc: 0.9370\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0453 - acc: 0.9852 - val_loss: 0.2932 - val_acc: 0.9320\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0434 - acc: 0.9851 - val_loss: 0.2883 - val_acc: 0.9340\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0444 - acc: 0.9854 - val_loss: 0.3200 - val_acc: 0.9250\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0424 - acc: 0.9855 - val_loss: 0.3021 - val_acc: 0.9300\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0483 - acc: 0.9856 - val_loss: 0.3040 - val_acc: 0.9380\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0458 - acc: 0.9853 - val_loss: 0.2969 - val_acc: 0.9320\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0436 - acc: 0.9858 - val_loss: 0.2587 - val_acc: 0.9380\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0409 - acc: 0.9881 - val_loss: 0.2723 - val_acc: 0.9370\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0409 - acc: 0.9874 - val_loss: 0.2625 - val_acc: 0.9430\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0418 - acc: 0.9870 - val_loss: 0.2714 - val_acc: 0.9410\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0328 - acc: 0.9899 - val_loss: 0.3220 - val_acc: 0.9300\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0399 - acc: 0.9874 - val_loss: 0.3009 - val_acc: 0.9340\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.2987 - val_acc: 0.9390\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0381 - acc: 0.9882 - val_loss: 0.3295 - val_acc: 0.9300\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0410 - acc: 0.9866 - val_loss: 0.2651 - val_acc: 0.9410\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0351 - acc: 0.9883 - val_loss: 0.3474 - val_acc: 0.9240\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0368 - acc: 0.9893 - val_loss: 0.3242 - val_acc: 0.9360\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0344 - acc: 0.9889 - val_loss: 0.2541 - val_acc: 0.9430\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0296 - acc: 0.9907 - val_loss: 0.3499 - val_acc: 0.9320\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0351 - acc: 0.9892 - val_loss: 0.2869 - val_acc: 0.9390\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0341 - acc: 0.9900 - val_loss: 0.3125 - val_acc: 0.9340\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0322 - acc: 0.9909 - val_loss: 0.3196 - val_acc: 0.9390\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0324 - acc: 0.9900 - val_loss: 0.2855 - val_acc: 0.9390\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0384 - acc: 0.9910 - val_loss: 0.2818 - val_acc: 0.9380\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0299 - acc: 0.9911 - val_loss: 0.2812 - val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = os.getenv('HOME')+'/aiffel/babi_memory_net/data/model.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2812 - acc: 0.9450\n",
      "\n",
      " 테스트 정확도: 0.9450\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문                |실제값  |예측값\n",
      "---------------------------------------\n",
      "은경이 는 어디 야 ?        : 복도      복도\n",
      "필웅이 는 어디 야 ?        : 화장실     화장실\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 사무실     사무실\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "필웅이 는 어디 야 ?        : 부엌      부엌\n",
      "필웅이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "은경이 는 어디 야 ?        : 정원      정원\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "필웅이 는 어디 야 ?        : 복도      복도\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "수종이 는 어디 야 ?        : 침실      침실\n",
      "경임이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n"
     ]
    }
   ],
   "source": [
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:7} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. postprocessor로 불용어제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'는': 1, '.': 2, '로': 3, '했습니다': 4, '으로': 5, '경임이': 6, '은경이': 7, '수종이': 8, '필웅이': 9, '이동': 10, '가버렸습니다': 11, '뛰어갔습니다': 12, '복귀': 13, '화장실': 14, '정원': 15, '복도': 16, '갔습니다': 17, '사무실': 18, '부엌': 19, '침실': 20, '어디': 21, '야': 22, '?': 23}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Postprocessor\n",
    "\n",
    "stopwords = {'는',  '로', '으로', '야'}\n",
    "postprocessor = Postprocessor(\n",
    "    base_tagger = twitter,\n",
    "    stopwords = stopwords)\n",
    "\n",
    "def tokenize2(sent):\n",
    "    sent_list = []\n",
    "    sent = postprocessor.pos(sent)\n",
    "    for a in range(len(sent)):\n",
    "        sent_1 = sent[a][0]\n",
    "        sent_list.append(sent_1)\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['은경이', '는', '어디', '야', '?']\n",
      "{'은경이': 1, '는': 2, '어디': 3, '야': 4, '?': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0038/anaconda3/envs/aiffel/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('수종이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Noun')\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('필웅이', 'Noun')\n",
    "\n",
    "counter2 = FreqDist()\n",
    "sent = '은경이는 어디야?'\n",
    "test2 = twitter.morphs(sent)\n",
    "print(test2)\n",
    "for word in test2:\n",
    "    counter2[word] +=1\n",
    "\n",
    "word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter2.most_common())}\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5]\n"
     ]
    }
   ],
   "source": [
    "sents = ['은경이는 어디야?', '철수는 집에 있어?']\n",
    "test_len = []\n",
    "test_list = []\n",
    "counter = FreqDist()\n",
    "for sent in sents:\n",
    "    test = postprocessor.pos(sent)\n",
    "    test_len.append(len(test))\n",
    "    for a in range(len(test)):\n",
    "        test_1 = test[a][0]\n",
    "        test_list.append(test_1)\n",
    "    for word in test_list:\n",
    "        counter[word] +=1\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    story_list = []\n",
    "    question_list = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            first_stories = postprocessor.pos(flatten(story))\n",
    "            story_len.append(len(first_stories))\n",
    "            for a in range(len(first_stories)):\n",
    "                stories_1 = first_stories[a][0]\n",
    "                story_list.append(stories_1)\n",
    "        for word in story_list: # 단어 집합에 단어 추가\n",
    "            counter[word] += 1\n",
    "        for question in questions:\n",
    "            first_question = postprocessor.pos(flatten(question))\n",
    "            question_len.append(len(first_question))\n",
    "            for a in range(len(first_question)):\n",
    "                question_1 = first_question[a][0]\n",
    "                question_list.append(question_1)\n",
    "        for word in question_list:\n",
    "             counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize2(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(story_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 1, '했습니다': 2, '경임이': 3, '은경이': 4, '수종이': 5, '필웅이': 6, '이동': 7, '뛰어갔습니다': 8, '가버렸습니다': 9, '복귀': 10, '갔습니다': 11, '화장실': 12, '복도': 13, '정원': 14, '사무실': 15, '부엌': 16, '침실': 17, '어디': 18, '?': 19}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 토큰화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize2(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize2(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50) (10000, 3) (10000, 20) (1000, 50) (1000, 3) (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : Tensor(\"input_7:0\", shape=(None, 50), dtype=float32)\n",
      "Question: Tensor(\"input_8:0\", shape=(None, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m Tensor(\"sequential_9/Identity:0\", shape=(None, 50, 50), dtype=float32)\n",
      "Input encoded c Tensor(\"sequential_10/Identity:0\", shape=(None, 50, 3), dtype=float32)\n",
      "Question encoded Tensor(\"sequential_11/Identity:0\", shape=(None, 3, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape Tensor(\"activation_6/Identity:0\", shape=(None, 50, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response shape Tensor(\"permute_3/Identity:0\", shape=(None, 3, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer shape Tensor(\"concatenate_3/Identity:0\", shape=(None, 3, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8931 - acc: 0.1670 - val_loss: 1.7924 - val_acc: 0.2430\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.7702 - acc: 0.2058 - val_loss: 1.6680 - val_acc: 0.2750\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6660 - acc: 0.2752 - val_loss: 1.6090 - val_acc: 0.3280\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6061 - acc: 0.3257 - val_loss: 1.5162 - val_acc: 0.3680\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5385 - acc: 0.3702 - val_loss: 1.4812 - val_acc: 0.4100\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5047 - acc: 0.4062 - val_loss: 1.4674 - val_acc: 0.3960\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4701 - acc: 0.4217 - val_loss: 1.4124 - val_acc: 0.4320\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4069 - acc: 0.4572 - val_loss: 1.3636 - val_acc: 0.4360\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3876 - acc: 0.4565 - val_loss: 1.3467 - val_acc: 0.4630\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3728 - acc: 0.4602 - val_loss: 1.3430 - val_acc: 0.4650\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3651 - acc: 0.4629 - val_loss: 1.3287 - val_acc: 0.4770\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3449 - acc: 0.4736 - val_loss: 1.3409 - val_acc: 0.4610\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3378 - acc: 0.4804 - val_loss: 1.3282 - val_acc: 0.4740\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3266 - acc: 0.4813 - val_loss: 1.2980 - val_acc: 0.4960\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3152 - acc: 0.4945 - val_loss: 1.3143 - val_acc: 0.4890\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3130 - acc: 0.4910 - val_loss: 1.2837 - val_acc: 0.5050\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2912 - acc: 0.5054 - val_loss: 1.2711 - val_acc: 0.5180\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2806 - acc: 0.5054 - val_loss: 1.2650 - val_acc: 0.5070\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2696 - acc: 0.5096 - val_loss: 1.2649 - val_acc: 0.5160\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2575 - acc: 0.5156 - val_loss: 1.2475 - val_acc: 0.5160\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2453 - acc: 0.5199 - val_loss: 1.2538 - val_acc: 0.5210\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2447 - acc: 0.5180 - val_loss: 1.2458 - val_acc: 0.5180\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2271 - acc: 0.5298 - val_loss: 1.2403 - val_acc: 0.5160\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2289 - acc: 0.5200 - val_loss: 1.2502 - val_acc: 0.5110\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2248 - acc: 0.5247 - val_loss: 1.2379 - val_acc: 0.5200\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2119 - acc: 0.5259 - val_loss: 1.2478 - val_acc: 0.5060\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2017 - acc: 0.5280 - val_loss: 1.2402 - val_acc: 0.5190\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1993 - acc: 0.5345 - val_loss: 1.2189 - val_acc: 0.5240\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1833 - acc: 0.5424 - val_loss: 1.1940 - val_acc: 0.5500\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1468 - acc: 0.5699 - val_loss: 1.1366 - val_acc: 0.5850\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1065 - acc: 0.5882 - val_loss: 1.0926 - val_acc: 0.6000\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0206 - acc: 0.6301 - val_loss: 1.0168 - val_acc: 0.6360\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9428 - acc: 0.6643 - val_loss: 0.9327 - val_acc: 0.6860\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8759 - acc: 0.6918 - val_loss: 0.8454 - val_acc: 0.7050\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8164 - acc: 0.7209 - val_loss: 0.7703 - val_acc: 0.7340\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7612 - acc: 0.7369 - val_loss: 0.7307 - val_acc: 0.7460\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7149 - acc: 0.7504 - val_loss: 0.6636 - val_acc: 0.7720\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6547 - acc: 0.7670 - val_loss: 0.6275 - val_acc: 0.7790\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6223 - acc: 0.7722 - val_loss: 0.5886 - val_acc: 0.7800\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5813 - acc: 0.7910 - val_loss: 0.5967 - val_acc: 0.7940\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5566 - acc: 0.8009 - val_loss: 0.5371 - val_acc: 0.8070\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5374 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.8220\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5106 - acc: 0.8149 - val_loss: 0.4945 - val_acc: 0.8200\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4913 - acc: 0.8197 - val_loss: 0.5141 - val_acc: 0.8190\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4703 - acc: 0.8281 - val_loss: 0.4802 - val_acc: 0.8200\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4647 - acc: 0.8265 - val_loss: 0.4687 - val_acc: 0.8240\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4489 - acc: 0.8342 - val_loss: 0.4621 - val_acc: 0.8270\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4438 - acc: 0.8343 - val_loss: 0.4518 - val_acc: 0.8390\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4346 - acc: 0.8419 - val_loss: 0.4673 - val_acc: 0.8210\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4273 - acc: 0.8445 - val_loss: 0.4627 - val_acc: 0.8200\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4098 - acc: 0.8468 - val_loss: 0.4659 - val_acc: 0.8310\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4058 - acc: 0.8473 - val_loss: 0.4890 - val_acc: 0.8290\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3981 - acc: 0.8540 - val_loss: 0.4851 - val_acc: 0.8280\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3950 - acc: 0.8559 - val_loss: 0.4465 - val_acc: 0.8310\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3898 - acc: 0.8567 - val_loss: 0.4453 - val_acc: 0.8250\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3813 - acc: 0.8586 - val_loss: 0.4345 - val_acc: 0.8290\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3721 - acc: 0.8598 - val_loss: 0.4201 - val_acc: 0.8400\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3723 - acc: 0.8645 - val_loss: 0.4248 - val_acc: 0.8400\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3652 - acc: 0.8660 - val_loss: 0.4137 - val_acc: 0.8570\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3535 - acc: 0.8702 - val_loss: 0.4136 - val_acc: 0.8460\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3533 - acc: 0.8715 - val_loss: 0.4036 - val_acc: 0.8460\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3353 - acc: 0.8768 - val_loss: 0.3926 - val_acc: 0.8610\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3267 - acc: 0.8800 - val_loss: 0.3790 - val_acc: 0.8600\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3249 - acc: 0.8791 - val_loss: 0.3655 - val_acc: 0.8710\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3204 - acc: 0.8820 - val_loss: 0.3575 - val_acc: 0.8700\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3010 - acc: 0.8901 - val_loss: 0.3388 - val_acc: 0.8770\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2968 - acc: 0.8917 - val_loss: 0.3346 - val_acc: 0.8760\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2894 - acc: 0.8978 - val_loss: 0.3517 - val_acc: 0.8740\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2833 - acc: 0.9013 - val_loss: 0.3515 - val_acc: 0.8820\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2652 - acc: 0.9057 - val_loss: 0.3040 - val_acc: 0.9000\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2652 - acc: 0.9101 - val_loss: 0.2911 - val_acc: 0.8990\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2503 - acc: 0.9096 - val_loss: 0.2900 - val_acc: 0.8910\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2525 - acc: 0.9099 - val_loss: 0.2986 - val_acc: 0.8980\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2363 - acc: 0.9152 - val_loss: 0.2927 - val_acc: 0.8910\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2375 - acc: 0.9144 - val_loss: 0.2911 - val_acc: 0.8910\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2279 - acc: 0.9227 - val_loss: 0.2624 - val_acc: 0.9090\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2172 - acc: 0.9255 - val_loss: 0.2633 - val_acc: 0.9110\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2139 - acc: 0.9223 - val_loss: 0.2911 - val_acc: 0.8970\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2202 - acc: 0.9213 - val_loss: 0.2511 - val_acc: 0.9070\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2136 - acc: 0.9276 - val_loss: 0.2552 - val_acc: 0.9080\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2041 - acc: 0.9276 - val_loss: 0.2632 - val_acc: 0.9070\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2009 - acc: 0.9310 - val_loss: 0.2611 - val_acc: 0.9070\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1986 - acc: 0.9330 - val_loss: 0.2415 - val_acc: 0.9140\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1949 - acc: 0.9317 - val_loss: 0.2399 - val_acc: 0.9170\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1895 - acc: 0.9335 - val_loss: 0.2343 - val_acc: 0.9220\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1835 - acc: 0.9361 - val_loss: 0.2509 - val_acc: 0.9060\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1859 - acc: 0.9335 - val_loss: 0.2337 - val_acc: 0.9140\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1805 - acc: 0.9380 - val_loss: 0.2413 - val_acc: 0.9160\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1729 - acc: 0.9395 - val_loss: 0.2351 - val_acc: 0.9160\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1629 - acc: 0.9446 - val_loss: 0.2452 - val_acc: 0.9150\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1629 - acc: 0.9415 - val_loss: 0.2430 - val_acc: 0.9040\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1614 - acc: 0.9434 - val_loss: 0.2105 - val_acc: 0.9200\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1584 - acc: 0.9420 - val_loss: 0.2052 - val_acc: 0.9280\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1571 - acc: 0.9457 - val_loss: 0.2225 - val_acc: 0.9220\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1548 - acc: 0.9476 - val_loss: 0.1954 - val_acc: 0.9280\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1534 - acc: 0.9454 - val_loss: 0.1956 - val_acc: 0.9280\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1471 - acc: 0.9473 - val_loss: 0.1793 - val_acc: 0.9290\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1489 - acc: 0.9477 - val_loss: 0.2138 - val_acc: 0.9220\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1458 - acc: 0.9502 - val_loss: 0.2142 - val_acc: 0.9240\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1395 - acc: 0.9530 - val_loss: 0.1867 - val_acc: 0.9330\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1336 - acc: 0.9531 - val_loss: 0.1894 - val_acc: 0.9360\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1359 - acc: 0.9519 - val_loss: 0.1915 - val_acc: 0.9320\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1313 - acc: 0.9545 - val_loss: 0.1881 - val_acc: 0.9330\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1236 - acc: 0.9577 - val_loss: 0.1763 - val_acc: 0.9360\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1215 - acc: 0.9575 - val_loss: 0.1876 - val_acc: 0.9360\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1215 - acc: 0.9589 - val_loss: 0.1831 - val_acc: 0.9380\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1171 - acc: 0.9604 - val_loss: 0.1905 - val_acc: 0.9320\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1204 - acc: 0.9585 - val_loss: 0.1827 - val_acc: 0.9410\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1125 - acc: 0.9601 - val_loss: 0.1621 - val_acc: 0.9460\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1126 - acc: 0.9608 - val_loss: 0.1882 - val_acc: 0.9300\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1160 - acc: 0.9610 - val_loss: 0.1781 - val_acc: 0.9450\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1018 - acc: 0.9660 - val_loss: 0.1533 - val_acc: 0.9500\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1070 - acc: 0.9649 - val_loss: 0.1749 - val_acc: 0.9420\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1045 - acc: 0.9650 - val_loss: 0.1843 - val_acc: 0.9350\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0964 - acc: 0.9656 - val_loss: 0.1604 - val_acc: 0.9520\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1079 - acc: 0.9634 - val_loss: 0.1529 - val_acc: 0.9510\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1034 - acc: 0.9644 - val_loss: 0.1651 - val_acc: 0.9490\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1012 - acc: 0.9674 - val_loss: 0.1422 - val_acc: 0.9500\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0965 - acc: 0.9671 - val_loss: 0.1555 - val_acc: 0.9470\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1002 - acc: 0.9684 - val_loss: 0.1406 - val_acc: 0.9500\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = os.getenv('HOME')+'/aiffel/babi_memory_net/data/stopwords_model.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1406 - acc: 0.9500\n",
      "\n",
      " 테스트 정확도: 0.9500\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문                |실제값  |예측값\n",
      "---------------------------------------\n",
      "은경이 어디 ?            : 복도      복도\n",
      "필웅이 어디 ?            : 화장실     침실\n",
      "경임이 어디 ?            : 부엌      부엌\n",
      "경임이 어디 ?            : 복도      복도\n",
      "경임이 어디 ?            : 부엌      부엌\n",
      "경임이 어디 ?            : 복도      복도\n",
      "경임이 어디 ?            : 정원      정원\n",
      "수종이 어디 ?            : 복도      복도\n",
      "경임이 어디 ?            : 사무실     사무실\n",
      "수종이 어디 ?            : 사무실     사무실\n",
      "필웅이 어디 ?            : 부엌      부엌\n",
      "필웅이 어디 ?            : 정원      정원\n",
      "수종이 어디 ?            : 사무실     화장실\n",
      "필웅이 어디 ?            : 침실      침실\n",
      "필웅이 어디 ?            : 침실      침실\n",
      "은경이 어디 ?            : 부엌      부엌\n",
      "은경이 어디 ?            : 정원      정원\n",
      "은경이 어디 ?            : 부엌      부엌\n",
      "수종이 어디 ?            : 사무실     부엌\n",
      "은경이 어디 ?            : 부엌      복도\n",
      "필웅이 어디 ?            : 복도      복도\n",
      "은경이 어디 ?            : 사무실     사무실\n",
      "은경이 어디 ?            : 사무실     사무실\n",
      "경임이 어디 ?            : 복도      침실\n",
      "수종이 어디 ?            : 침실      정원\n",
      "경임이 어디 ?            : 침실      침실\n",
      "필웅이 어디 ?            : 침실      침실\n",
      "수종이 어디 ?            : 부엌      부엌\n",
      "수종이 어디 ?            : 부엌      화장실\n",
      "수종이 어디 ?            : 부엌      화장실\n"
     ]
    }
   ],
   "source": [
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:7} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 customized konlpy를 처음 써봤는데 생각보다 유용해서 좋았다.    \n",
    "postprocessor같은 경우 morphs 메서드가 없어서 list로 만들어주는 방식을 택했는데 시행착오를 계속 겪었다.    \n",
    "성능은 확실히 불용어를 제거해준 것이 제거하지 않은 것보다 성능이 훨씬 좋다는 것을 알 수 있었다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
