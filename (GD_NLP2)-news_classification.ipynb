{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로이터 뉴스 다중 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 단어수를 제한 두지 않고 머신러닝 기법으로 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f649b19a590>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(12,5)\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n",
       " \"<sos> generale de banque sa lt genb br and lt heller overseas corp of chicago have each taken 50 pct stakes in factoring company sa belgo factors generale de banque said in a statement it gave no financial details of the transaction sa belgo factors' turnover in 1986 was 17 5 billion belgian francs reuter 3\",\n",
       " '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in enron corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national intergroup inc of 11 8 mln and brae corp of 15 6 mln reuter 3',\n",
       " \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely delinquent borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in fmha's financial eligibility standards indicated as many as one half of fmha borrowers who received new loans from the agency in 1986 would be ineligible under the proposed system the agency has proposed evaluating applicants' credit using a variety of financial ratios instead of relying solely on cashflow ability senate agriculture committee chairman patrick leahy d vt slammed the proposed eligibility changes telling fmha administrator vance clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to administer its 70 billion dlr loan portfolio in a compassionate yet judicious manner crowley of gao congress' investigative arm said the proposed credit scoring system attempted to ensure that fmha would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\",\n",
       " '<sos> seton co said its board has received a proposal from chairman and chief executive officer philip d kaltenbacher to acquire seton for 15 75 dlrs per share in cash seton said the acquisition bid is subject to kaltenbacher arranging the necessary financing it said he intends to ask other members of senior management to participate the company said kaltenbacher owns 30 pct of seton stock and other management members another 7 5 pct seton said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to accommodate growth and expansion plans for waldbaum inc and shopwell inc over the next two years a and p said the acquisition of shopwell in august 1986 and waldbaum in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt tengelmann warenhandelsgesellschaft of west germany reuter 3',\n",
       " \"<sos> philippine sugar production in the 1987 88 crop year ending august has been set at 1 6 mln tonnes up from a provisional 1 3 mln tonnes this year sugar regulatory administration sra chairman arsenio yulo said yulo told reuters a survey during the current milling season which ends next month showed the 1986 87 estimate would almost certainly be met he said at least 1 2 mln tonnes of the 1987 88 crop would be earmarked for domestic consumption yulo said about 130 000 tonnes would be set aside for the u s sugar quota 150 000 tonnes for strategic reserves and 50 000 tonnes would be sold on the world market he said if the government approved a long standing sra recommendation to manufacture ethanol the project would take up another 150 000 tonnes slightly raising the target the government for its own reasons has been delaying approval of the project but we expect it to come through by july yulo said ethanol could make up five pct of gasoline cutting the oil import bill by about 300 mln pesos yulo said three major philippine distilleries were ready to start manufacturing ethanol if the project was approved the ethanol project would result in employment for about 100 000 people sharply reducing those thrown out of work by depressed world sugar prices and a moribund domestic industry production quotas set for the first time in 1987 88 had been submitted to president corazon aquino i think the president would rather wait till the new congress convenes after the may elections he said but there is really no need for such quotas we are right now producing just slightly over our own consumption level the producers have never enjoyed such high prices yulo said adding sugar was currently selling locally for 320 pesos per picul up from 190 pesos last august yulo said prices were driven up because of speculation following the sra's bid to control production we are no longer concerned so much with the world market he said adding producers in the negros region had learned from their mistakes and diversified into corn and prawn farming and cloth production he said diversification into products other than ethanol was also possible within the sugar industry the brazilians long ago learnt their lessons yulo said they have 300 sugar mills compared with our 41 but they relocated many of them and diversified production we want to call this a 'sugarcane industry' instead of the sugar industry he said sugarcane could be fed to pigs and livestock used for thatching roofs or used in room panelling when you cut sugarcane you don't even have to produce sugar he said yulo said the philippines was lobbying for a renewal of the international sugar agreement which expired in 1984 as a major sugar producer we are urging them to write a new agreement which would revive world prices yulo said if there is no agreement world prices will always be depressed particularly because the european community is subsidising its producers and dumping sugar on the markets he said current world prices holding steady at about 7 60 cents per pound were uneconomical for the philippines where production costs ranged from 12 to 14 cents a pound if the price holds steady for a while at 7 60 cents i expect the level to rise to about 11 cents a pound by the end of this year he said yulo said economists forecast a bullish sugar market by 1990 with world consumption outstripping production he said sugar markets were holding up despite encroachments from artificial sweeteners and high fructose corn syrup but we are not happy with the reagan administration he said since 1935 we have been regular suppliers of sugar to the u s in 1982 when they restored the quota system they cut ours in half without any justification manila was keenly watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\",\n",
       " \"<sos> the agriculture department's widening of louisiana gulf differentials will affect county posted prices for number two yellow corn in ten states a usda official said all counties in iowa will be affected as will counties which use the gulf to price corn in illinois indiana tennessee kentucky missouri mississippi arkansas alabama and louisiana said ron burgess deputy director of commodity operations division for the usda usda last night notified the grain industry that effective immediately all gulf differentials used to price interior corn would be widened on a sliding scale basis of four to eight cts depending on what the differential is usda's action was taken to lower excessively high posted county prices for corn caused by high gulf prices we've been following this louisiana gulf situation for a month and we don't think it's going to get back in line in any nearby time burgess said burgess said usda will probably narrow back the gulf differentials when and if gulf prices recede if we're off the mark now because we're too high wouldn't we be as much off the mark if we're too low he said while forecasting more adjustments if gulf prices fall burgess said no other changes in usda's price system are being planned right now we don't tinker we don't make changes lightly and we don't make changes often he said reuter 3\",\n",
       " '<sos> graham mccormick oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the oak hill and north rucias fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to prepay principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the noteholders exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3',\n",
       " '<sos> strong south easterly winds were keeping many vessels trapped in the ice off the finnish and swedish coasts in one of the worst icy periods in the baltic for many years the finnish board of navigation said in finland and sweden up to 50 vessels were reported to be stuck in the ice and even the largest of the assisting icebreakers were having difficulties in breaking through to the stranded ships coastguard officials said however icy conditions in the southern baltic at the soviet oil ports of ventspils and klaipeda had eased they said weather officials in neighbouring sweden said the icy conditions in the baltic were the worst for 30 years with ships fighting a losing battle to keep moving in the coastal stretches of the gulf of bothnia which divides finland and sweden the ice is up to one metre thick with drifts and currents packing it into almost impenetrable walls three metres high swedish coastguard officials said weather forecasts say winds may ease during the weekend but a further drop in temperature could bring shipping to a standstill the officials said reuter 3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5997328584149599\n",
      "f1_score: 0.06767886443611608\n"
     ]
    }
   ],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "\n",
    "predicted = mod.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7649154051647373\n",
      "f1_score: 0.4639854358945848\n"
     ]
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "predicted = cb.predict(tfidfv_test) \n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.813446126447017\n",
      "f1_score: 0.669532685925375\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10000,penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "predicted = lr.predict(tfidfv_test) \n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7773820124666073\n",
      "f1_score: 0.5762216069486185\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "predicted = lsvc.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6211041852181657\n",
      "f1_score: 0.15450055404800783\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "predicted = tree.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6544968833481746\n",
      "f1_score: 0.2794631711818573\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "predicted = forest.predict(tfidfv_test) \n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7702582368655387\n",
      "f1_score: 0.572792648567258\n"
     ]
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0)# verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "predicted = grbt.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8187889581478184\n",
      "f1_score: 0.6577141879659247\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "predicted = voting_classifier.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 단어를 5000개로 제한하고 머신러닝 기법으로 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}\n",
    "\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6731967943009796\n",
      "f1_score: 0.11017286132336847\n"
     ]
    }
   ],
   "source": [
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)\n",
    "x_test_dtm = dtmvector.transform(x_test) \n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
    "\n",
    "predicted = mod.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7707034728406055\n",
      "f1_score: 0.48203488372044917\n"
     ]
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "predicted = cb.predict(tfidfv_test) \n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8058771148708815\n",
      "f1_score: 0.6427529674429183\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10000,penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "predicted = lr.predict(tfidfv_test) \n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7666963490650045\n",
      "f1_score: 0.5774682817643806\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "predicted = lsvc.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6179875333926982\n",
      "f1_score: 0.17794649395239356\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "predicted = tree.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.701246660730187\n",
      "f1_score: 0.35960899933378104\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "predicted = forest.predict(tfidfv_test) \n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.767586821015138\n",
      "f1_score: 0.5791898381470704\n"
     ]
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0)# verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "predicted = grbt.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8161175422974176\n",
      "f1_score: 0.6642429726937643\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "predicted = voting_classifier.predict(tfidfv_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, predicted))\n",
    "print('f1_score:', f1_score(y_test, predicted, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting과 Voting을 제외하고 단어 수를 5000개로 제한한 경우가 단어수를 제한하지 않은 경우보다 정확도나 f1_score가 높았다.  \n",
    "그러나 Boosting 혹은 Voting을 할 경우 둘의 정확도나 f1_score는 거의 비슷한 곳에 수렴된다.    \n",
    "그리고 Decision Tree는 단어수에 상관없이 가장 낮은 정확도를 갖고 있다.    \n",
    "결론적으로 단어수 제한한 것이 단어수를 제한하지 않은 것보다 성능이 좋다고 얘기할 수 있다.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM으로 뉴스 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = 5000, test_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 120)         600000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 120)               115680    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                5566      \n",
      "=================================================================\n",
      "Total params: 721,246\n",
      "Trainable params: 721,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 120))\n",
    "model.add(LSTM(120))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc', f1_m, precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.6896 - acc: 0.3443 - f1_m: 0.0185 - precision_m: 0.0185 - recall_m: 0.0185 \n",
      "Epoch 00001: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 23ms/step - loss: 2.6896 - acc: 0.3443 - f1_m: 0.0185 - precision_m: 0.0185 - recall_m: 0.0185 - val_loss: 2.4100 - val_acc: 0.3255 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/60\n",
      "54/57 [===========================>..] - ETA: 0s - loss: 2.1446 - acc: 0.4622 - f1_m: 0.3322 - precision_m: 0.7956 - recall_m: 0.2154 \n",
      "Epoch 00002: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 2.1388 - acc: 0.4633 - f1_m: 0.3404 - precision_m: 0.8033 - recall_m: 0.2220 - val_loss: 2.0903 - val_acc: 0.4396 - val_f1_m: 0.4180 - val_precision_m: 0.8307 - val_recall_m: 0.2803\n",
      "Epoch 3/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.8279 - acc: 0.5174 - f1_m: 0.5425 - precision_m: 0.8683 - recall_m: 0.4012\n",
      "Epoch 00003: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 1.8274 - acc: 0.5177 - f1_m: 0.5463 - precision_m: 0.8691 - recall_m: 0.4055 - val_loss: 1.8582 - val_acc: 0.5192 - val_f1_m: 0.5365 - val_precision_m: 0.8995 - val_recall_m: 0.3829\n",
      "Epoch 4/60\n",
      "54/57 [===========================>..] - ETA: 0s - loss: 1.6700 - acc: 0.5615 - f1_m: 0.6130 - precision_m: 0.8634 - recall_m: 0.4773\n",
      "Epoch 00004: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 1.6688 - acc: 0.5626 - f1_m: 0.6166 - precision_m: 0.8666 - recall_m: 0.4808 - val_loss: 1.7238 - val_acc: 0.5531 - val_f1_m: 0.6003 - val_precision_m: 0.8737 - val_recall_m: 0.4584\n",
      "Epoch 5/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.5557 - acc: 0.5953 - f1_m: 0.6460 - precision_m: 0.8987 - recall_m: 0.5059\n",
      "Epoch 00005: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 1.5573 - acc: 0.5951 - f1_m: 0.6455 - precision_m: 0.8986 - recall_m: 0.5052 - val_loss: 1.7145 - val_acc: 0.5459 - val_f1_m: 0.5823 - val_precision_m: 0.8909 - val_recall_m: 0.4334\n",
      "Epoch 6/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.4287 - acc: 0.6267 - f1_m: 0.6626 - precision_m: 0.9231 - recall_m: 0.5187\n",
      "Epoch 00006: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 1.4318 - acc: 0.6262 - f1_m: 0.6594 - precision_m: 0.9200 - recall_m: 0.5158 - val_loss: 1.6252 - val_acc: 0.5893 - val_f1_m: 0.6131 - val_precision_m: 0.8656 - val_recall_m: 0.4761\n",
      "Epoch 7/60\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.3452 - acc: 0.6487 - f1_m: 0.6715 - precision_m: 0.9249 - recall_m: 0.5283\n",
      "Epoch 00007: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 1.3452 - acc: 0.6487 - f1_m: 0.6715 - precision_m: 0.9249 - recall_m: 0.5283 - val_loss: 1.5537 - val_acc: 0.5921 - val_f1_m: 0.6250 - val_precision_m: 0.8679 - val_recall_m: 0.4902\n",
      "Epoch 8/60\n",
      "55/57 [===========================>..] - ETA: 0s - loss: 1.2086 - acc: 0.6864 - f1_m: 0.7103 - precision_m: 0.9216 - recall_m: 0.5790\n",
      "Epoch 00008: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.2029 - acc: 0.6880 - f1_m: 0.7145 - precision_m: 0.9233 - recall_m: 0.5842 - val_loss: 1.4858 - val_acc: 0.6283 - val_f1_m: 0.6437 - val_precision_m: 0.8756 - val_recall_m: 0.5110\n",
      "Epoch 9/60\n",
      "55/57 [===========================>..] - ETA: 0s - loss: 1.0753 - acc: 0.7180 - f1_m: 0.7515 - precision_m: 0.9138 - recall_m: 0.6396\n",
      "Epoch 00009: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 1.0774 - acc: 0.7177 - f1_m: 0.7538 - precision_m: 0.9141 - recall_m: 0.6429 - val_loss: 1.5109 - val_acc: 0.6266 - val_f1_m: 0.6540 - val_precision_m: 0.8386 - val_recall_m: 0.5397\n",
      "Epoch 10/60\n",
      "55/57 [===========================>..] - ETA: 0s - loss: 0.9507 - acc: 0.7548 - f1_m: 0.7782 - precision_m: 0.9153 - recall_m: 0.6778\n",
      "Epoch 00010: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.9527 - acc: 0.7548 - f1_m: 0.7767 - precision_m: 0.9130 - recall_m: 0.6768 - val_loss: 1.4720 - val_acc: 0.6366 - val_f1_m: 0.6670 - val_precision_m: 0.8228 - val_recall_m: 0.5619\n",
      "Epoch 11/60\n",
      "54/57 [===========================>..] - ETA: 0s - loss: 0.8528 - acc: 0.7760 - f1_m: 0.8006 - precision_m: 0.9283 - recall_m: 0.7047\n",
      "Epoch 00011: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.8495 - acc: 0.7769 - f1_m: 0.8005 - precision_m: 0.9267 - recall_m: 0.7056 - val_loss: 1.4594 - val_acc: 0.6505 - val_f1_m: 0.6825 - val_precision_m: 0.7870 - val_recall_m: 0.6030\n",
      "Epoch 12/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.7545 - acc: 0.8019 - f1_m: 0.8217 - precision_m: 0.9325 - recall_m: 0.7352\n",
      "Epoch 00012: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.7553 - acc: 0.8015 - f1_m: 0.8185 - precision_m: 0.9305 - recall_m: 0.7316 - val_loss: 1.6055 - val_acc: 0.6227 - val_f1_m: 0.6497 - val_precision_m: 0.7480 - val_recall_m: 0.5749\n",
      "Epoch 13/60\n",
      "55/57 [===========================>..] - ETA: 0s - loss: 0.7094 - acc: 0.8111 - f1_m: 0.8269 - precision_m: 0.9340 - recall_m: 0.7425\n",
      "Epoch 00013: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.7071 - acc: 0.8121 - f1_m: 0.8268 - precision_m: 0.9341 - recall_m: 0.7422 - val_loss: 1.4803 - val_acc: 0.6628 - val_f1_m: 0.6801 - val_precision_m: 0.7847 - val_recall_m: 0.6009\n",
      "Epoch 14/60\n",
      "55/57 [===========================>..] - ETA: 0s - loss: 0.6040 - acc: 0.8408 - f1_m: 0.8491 - precision_m: 0.9431 - recall_m: 0.7730\n",
      "Epoch 00014: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.6072 - acc: 0.8402 - f1_m: 0.8485 - precision_m: 0.9431 - recall_m: 0.7719 - val_loss: 1.4920 - val_acc: 0.6678 - val_f1_m: 0.6826 - val_precision_m: 0.7659 - val_recall_m: 0.6171\n",
      "Epoch 15/60\n",
      "54/57 [===========================>..] - ETA: 0s - loss: 0.5499 - acc: 0.8545 - f1_m: 0.8598 - precision_m: 0.9417 - recall_m: 0.7915\n",
      "Epoch 00015: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.5507 - acc: 0.8539 - f1_m: 0.8591 - precision_m: 0.9418 - recall_m: 0.7902 - val_loss: 1.5984 - val_acc: 0.6722 - val_f1_m: 0.6910 - val_precision_m: 0.7723 - val_recall_m: 0.6254\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=60, callbacks=[es, mc], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6491540670394897\n",
      "f1_score: 0.6789284348487854\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('accuracy:', accuracy)\n",
    "print('f1_score:', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['acc']) + 1)\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실험에서의 정확도를 보면 DecisionTree나 Multinomial Naive Bayes를 제외하고 정확도가 매우 낮다.    \n",
    "그러나 f1_score입장에서는 상황이 다르다. LSTM의 f1_score는 67%로 앞선 머신러닝보다 훨씬 성능이 좋다고 볼 수 있다.    \n",
    "특히 이번 데이터 같은 경우 label간 불균형이 존재하기 때문에 f1_score가 정확도보다 더 좋은 지표라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 불용어를 제거하고 전처리과정까지 거친 상태에서 LSTM으로 다중분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = 5000, test_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index + 3 : word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(X_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in X_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "X_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(X_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in X_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "X_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sos unk unk said result december acquisition space co expects earnings per share dlrs per share cts company said pretax net rise nine mln dlrs six mln dlrs rental operation revenues mln dlrs mln dlrs said cash flow per share year three dlrs reuter',\n",
       " 'sos generale de banque sa lt unk unk lt heller overseas corp chicago taken pct stakes unk company sa unk factors generale de banque said statement gave financial details transaction sa unk unk turnover billion belgian francs reuter',\n",
       " 'sos shr dlrs vs cts shr diluted dlrs vs cts net mln vs avg shrs mln vs mln year shr dlrs vs dlrs shr diluted dlrs vs dlrs net mln vs mln avg shrs mln vs mln note earnings per share reflect two one split effective january per share amounts calculated preferred stock dividends loss continuing operations qtr includes gains sale investments unk corp mln dlrs associated companies less writedowns investments national unk inc mln unk corp mln reuter',\n",
       " 'sos farmers home administration agriculture department farm lending arm could lose seven billion dlrs outstanding principal severely unk borrowers one fourth farm loan portfolio general accounting office gao said remarks prepared delivery senate agriculture committee brian unk senior associate director gao also said preliminary analysis proposed changes unk financial unk standards indicated many one half unk borrowers received new loans agency would unk proposed system agency proposed unk unk credit using variety financial unk instead unk unk unk ability senate agriculture committee chairman unk unk unk unk proposed unk changes telling unk administrator unk clark hearing would mark dramatic shift unk purpose away unk unk last unk toward becoming big city bank clark unk new regulations saying agency responsibility unk billion dlr loan portfolio unk yet unk manner unk gao unk unk arm said proposed credit unk system attempted ensure unk would make loans borrowers reasonable change unk debt reuter',\n",
       " 'sos unk co said board received proposal chairman chief executive officer philip unk acquire unk dlrs per share cash unk said acquisition bid subject unk arranging necessary financing said intends ask members senior management participate company said unk owns pct unk stock management members another pct unk said formed independent board committee consider offer deferred annual meeting scheduled march reuter']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in X_train:\n",
    "    X_train_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "X_train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sos great atlantic pacific tea co said three year mln dlr capital program substantially increased unk growth expansion plans unk inc unk inc next two years said acquisition unk august unk december helped us achieve better expected results fourth quarter ended february net income continuing operations jumped pct mln dlrs cts share latest quarter sales increased pct billion dlrs gave details expanded capital program say completed first year program pct owned lt unk unk west germany reuter',\n",
       " 'sos philippine sugar production crop year ending august set mln tonnes provisional mln tonnes year sugar regulatory administration unk chairman unk unk said unk told reuters survey current milling season ends next month showed estimate would almost certainly met said least mln tonnes crop would unk domestic consumption unk said tonnes would set aside sugar quota tonnes strategic reserves tonnes would sold world market said government approved long standing unk recommendation manufacture unk project would take another tonnes slightly raising target government reasons unk approval project expect come july unk said unk could make five pct gasoline cutting oil import bill mln pesos unk said three major philippine unk ready start manufacturing unk project approved unk project would result employment people sharply reducing unk work depressed world sugar prices unk domestic industry production quotas set first time submitted president unk unk think president would rather wait unk new congress unk may elections said really need quotas right producing slightly consumption level producers never unk high prices unk said adding sugar currently selling unk pesos per unk pesos last august unk said prices unk speculation following unk bid control production longer concerned much world market said adding producers unk region unk unk diversified corn unk unk unk production said unk products unk also possible within sugar industry unk long ago unk unk unk said sugar mills compared unk many diversified production want call unk unk instead sugar industry said unk could fed unk livestock used unk unk used room unk cut unk even produce sugar said unk said philippines unk renewal international sugar agreement expired major sugar producer urging write new agreement would unk world prices unk said agreement world prices always depressed particularly european community unk producers dumping sugar markets said current world prices holding steady cents per pound unk philippines production costs ranged cents pound price holds steady cents expect level rise cents pound end year said unk said economists forecast bullish sugar market world consumption unk production said sugar markets holding despite unk unk unk high unk corn unk happy reagan administration said since unk regular suppliers sugar restored quota system cut unk half without unk unk unk unk washington moves cut domestic support prices cents pound cents agriculture department last december unk month sugar import quota philippines short tons short tons unk said despite next year increased production target philippine mills expected shut least four mills working season said expect two three follow suit next season reuter',\n",
       " 'sos agriculture department widening louisiana gulf differentials affect county posted prices number two unk corn ten states usda official said unk iowa affected unk use gulf price corn illinois indiana unk unk missouri mississippi unk unk louisiana said unk unk deputy director commodity operations division usda usda last night unk grain industry effective immediately gulf differentials used price interior corn would widened unk scale basis four eight cts depending differential usda action taken lower unk high posted county prices corn caused high gulf prices following louisiana gulf situation month think going get back line nearby time unk said unk said usda probably narrow back gulf differentials gulf prices unk mark high unk much mark low said forecasting adjustments gulf prices fall unk said changes usda price system planned right unk make changes unk make changes often said reuter',\n",
       " 'sos unk unk oil gas partnership said completed sale interests two major oil gas fields lt energy assets international corp mln dlrs company said sold one half pct interest unk hill north unk fields two largest producing properties said used mln dlrs proceeds unk principal senior secured notes semi annual principal payments remaining mln dlrs notes satisfied december result said company said note agreements amended reflect easing financial unk increase interest pct pct december said unk exercise price warrants also reduced cts dlrs company said energy assets agreed share costs increasing production unk hill field reuter',\n",
       " 'sos strong south unk winds keeping many vessels unk ice unk swedish unk one worst unk periods baltic many years unk board navigation said unk sweden vessels reported unk ice even largest unk unk difficulties breaking unk ships unk officials said however unk conditions southern baltic soviet oil ports unk unk eased said weather officials unk sweden said unk conditions baltic worst years ships fighting losing battle keep moving coastal unk gulf unk unk unk sweden ice one unk unk unk unk unk almost unk unk three metres high swedish unk officials said weather forecasts say winds may ease weekend drop unk could bring shipping standstill officials said reuter']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in X_test:\n",
    "    X_test_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "X_test_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스의 최대 길이 :5828\n",
      "훈련용 뉴스의 평균 길이 :548.8563794255177\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in X_train_text)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, X_train_text))/len(X_train_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "train_tokenizer = Tokenizer(num_words = 5000)\n",
    "train_tokenizer.fit_on_texts(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_tokenizer.texts_to_sequences(X_train_text)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = train_tokenizer.texts_to_sequences(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen = 600, padding = 'pre')\n",
    "X_test = pad_sequences(X_test, maxlen = 600, padding = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 120)         600000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 120)               115680    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                5566      \n",
      "=================================================================\n",
      "Total params: 721,246\n",
      "Trainable params: 721,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 120))\n",
    "model.add(LSTM(120))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 2.6837 - acc: 0.3384 - f1_m: 0.0264 - precision_m: 0.0264 - recall_m: 0.0264\n",
      "Epoch 00001: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 4s 62ms/step - loss: 2.6819 - acc: 0.3389 - f1_m: 0.0259 - precision_m: 0.0260 - recall_m: 0.0259 - val_loss: 2.4421 - val_acc: 0.3255 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 2.0955 - acc: 0.4612 - f1_m: 0.3207 - precision_m: 0.6122 - recall_m: 0.2203\n",
      "Epoch 00002: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 2.0946 - acc: 0.4615 - f1_m: 0.3242 - precision_m: 0.6137 - recall_m: 0.2236 - val_loss: 1.9470 - val_acc: 0.5058 - val_f1_m: 0.5395 - val_precision_m: 0.7640 - val_recall_m: 0.4183\n",
      "Epoch 3/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.7229 - acc: 0.5456 - f1_m: 0.5838 - precision_m: 0.8438 - recall_m: 0.4502\n",
      "Epoch 00003: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 1.7218 - acc: 0.5459 - f1_m: 0.5873 - precision_m: 0.8466 - recall_m: 0.4536 - val_loss: 1.7239 - val_acc: 0.5515 - val_f1_m: 0.6091 - val_precision_m: 0.8721 - val_recall_m: 0.4694\n",
      "Epoch 4/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.5801 - acc: 0.6083 - f1_m: 0.6515 - precision_m: 0.8947 - recall_m: 0.5141\n",
      "Epoch 00004: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 1.5802 - acc: 0.6082 - f1_m: 0.6503 - precision_m: 0.8966 - recall_m: 0.5123 - val_loss: 1.7496 - val_acc: 0.5442 - val_f1_m: 0.5950 - val_precision_m: 0.8519 - val_recall_m: 0.4584\n",
      "Epoch 5/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.4471 - acc: 0.6410 - f1_m: 0.6663 - precision_m: 0.9118 - recall_m: 0.5262\n",
      "Epoch 00005: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 3s 57ms/step - loss: 1.4491 - acc: 0.6404 - f1_m: 0.6634 - precision_m: 0.9108 - recall_m: 0.5232 - val_loss: 1.5541 - val_acc: 0.6144 - val_f1_m: 0.6332 - val_precision_m: 0.8409 - val_recall_m: 0.5105\n",
      "Epoch 6/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.2664 - acc: 0.6826 - f1_m: 0.6984 - precision_m: 0.9105 - recall_m: 0.5679\n",
      "Epoch 00006: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 1.2658 - acc: 0.6828 - f1_m: 0.6997 - precision_m: 0.9095 - recall_m: 0.5704 - val_loss: 1.3897 - val_acc: 0.6533 - val_f1_m: 0.6965 - val_precision_m: 0.8672 - val_recall_m: 0.5827\n",
      "Epoch 7/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.0948 - acc: 0.7157 - f1_m: 0.7576 - precision_m: 0.9040 - recall_m: 0.6535\n",
      "Epoch 00007: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 1.0949 - acc: 0.7158 - f1_m: 0.7588 - precision_m: 0.9057 - recall_m: 0.6544 - val_loss: 1.3733 - val_acc: 0.6600 - val_f1_m: 0.6784 - val_precision_m: 0.8874 - val_recall_m: 0.5522\n",
      "Epoch 8/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 1.0040 - acc: 0.7468 - f1_m: 0.7696 - precision_m: 0.9023 - recall_m: 0.6724\n",
      "Epoch 00008: val_acc did not improve from 0.68923\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 1.0025 - acc: 0.7473 - f1_m: 0.7726 - precision_m: 0.9040 - recall_m: 0.6761 - val_loss: 1.3287 - val_acc: 0.6656 - val_f1_m: 0.7029 - val_precision_m: 0.8589 - val_recall_m: 0.5957\n",
      "Epoch 9/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.8875 - acc: 0.7793 - f1_m: 0.7957 - precision_m: 0.9235 - recall_m: 0.6998\n",
      "Epoch 00009: val_acc improved from 0.68923 to 0.70896, saving model to best_model.h5\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.8865 - acc: 0.7795 - f1_m: 0.7971 - precision_m: 0.9237 - recall_m: 0.7019 - val_loss: 1.2006 - val_acc: 0.7090 - val_f1_m: 0.7229 - val_precision_m: 0.8325 - val_recall_m: 0.6395\n",
      "Epoch 10/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.7691 - acc: 0.8069 - f1_m: 0.8174 - precision_m: 0.9267 - recall_m: 0.7320\n",
      "Epoch 00010: val_acc improved from 0.70896 to 0.71731, saving model to best_model.h5\n",
      "57/57 [==============================] - 3s 57ms/step - loss: 0.7690 - acc: 0.8065 - f1_m: 0.8163 - precision_m: 0.9265 - recall_m: 0.7305 - val_loss: 1.1880 - val_acc: 0.7173 - val_f1_m: 0.7290 - val_precision_m: 0.8435 - val_recall_m: 0.6426\n",
      "Epoch 11/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.6920 - acc: 0.8230 - f1_m: 0.8329 - precision_m: 0.9301 - recall_m: 0.7547\n",
      "Epoch 00011: val_acc improved from 0.71731 to 0.72955, saving model to best_model.h5\n",
      "57/57 [==============================] - 3s 57ms/step - loss: 0.6926 - acc: 0.8228 - f1_m: 0.8316 - precision_m: 0.9299 - recall_m: 0.7529 - val_loss: 1.1349 - val_acc: 0.7295 - val_f1_m: 0.7425 - val_precision_m: 0.8349 - val_recall_m: 0.6697\n",
      "Epoch 12/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.8456 - f1_m: 0.8522 - precision_m: 0.9331 - recall_m: 0.7849\n",
      "Epoch 00012: val_acc did not improve from 0.72955\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.6030 - acc: 0.8454 - f1_m: 0.8508 - precision_m: 0.9318 - recall_m: 0.7835 - val_loss: 1.1940 - val_acc: 0.7195 - val_f1_m: 0.7294 - val_precision_m: 0.8156 - val_recall_m: 0.6608\n",
      "Epoch 13/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.5294 - acc: 0.8665 - f1_m: 0.8690 - precision_m: 0.9342 - recall_m: 0.8126\n",
      "Epoch 00013: val_acc improved from 0.72955 to 0.73400, saving model to best_model.h5\n",
      "57/57 [==============================] - 3s 57ms/step - loss: 0.5288 - acc: 0.8665 - f1_m: 0.8689 - precision_m: 0.9354 - recall_m: 0.8118 - val_loss: 1.2177 - val_acc: 0.7340 - val_f1_m: 0.7419 - val_precision_m: 0.8149 - val_recall_m: 0.6817\n",
      "Epoch 14/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.4681 - acc: 0.8860 - f1_m: 0.8806 - precision_m: 0.9420 - recall_m: 0.8271\n",
      "Epoch 00014: val_acc improved from 0.73400 to 0.74791, saving model to best_model.h5\n",
      "57/57 [==============================] - 3s 57ms/step - loss: 0.4679 - acc: 0.8860 - f1_m: 0.8811 - precision_m: 0.9420 - recall_m: 0.8281 - val_loss: 1.1773 - val_acc: 0.7479 - val_f1_m: 0.7543 - val_precision_m: 0.8149 - val_recall_m: 0.7030\n",
      "Epoch 15/60\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.9015 - f1_m: 0.8928 - precision_m: 0.9437 - recall_m: 0.8475\n",
      "Epoch 00015: val_acc did not improve from 0.74791\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.4111 - acc: 0.9016 - f1_m: 0.8931 - precision_m: 0.9436 - recall_m: 0.8481 - val_loss: 1.2604 - val_acc: 0.7112 - val_f1_m: 0.7258 - val_precision_m: 0.8034 - val_recall_m: 0.6629\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc', f1_m, precision_m, recall_m])\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=60, callbacks=[es], validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6985752582550049\n",
      "f1_score: 0.72484290599823\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('accuracy:', accuracy)\n",
    "print('f1_score:', f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 실험이 데이터가 불용어나 전처리과정을 거치치 않아 문제가 생겼다고 판단해서 전처리 이후 딥러닝 모델에 넣었다.    \n",
    "정확도는 앞선 실험보다 좋게 나타났지만 다른 머신러닝 알고리즘보다 성능이 낮다는 것을 알 수 있다.    \n",
    "그러나 f1_score는  72%로 성능이 더 개선되었다.   \n",
    "딥러닝이 머신러닝보다 조금 더 성능이 좋다는 것이 입증되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
